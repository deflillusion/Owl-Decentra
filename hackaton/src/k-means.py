import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from mpl_toolkits.mplot3d import Axes3D
import warnings
import os
import gc
warnings.filterwarnings('ignore')

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
categories = {
    'auto': [5541, 5542, 7513, 7531, 5599],
    'cosmetic': [5999, 7298, 5945, 5977],
    'fashion': [5651, 5699, 5691],
    'beauty_salons': [7230],
    'construction': [5311, 5310, 5122, 5712, 5200, 5211, 5722, 5732, 5734],
    'book_and_sports': [5941, 5942],
    'tax_payment': [9311],
    'travel': [3000, 3010, 3050, 3500, 7011]
}

transaction_types = {
    'incoming_transfer': ['P2P_IN'],
    'outgoing_transfer': ['P2P_OUT'],
    'ecom': ['ECOM'],
    'pos': ['POS'],
    'cash_withdrawal': ['ATM_WITHDRAWAL'],
    'salary': ['SALARY']
}

# –ü–æ—Ä–æ–≥ –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
min_currencies_travel = 3

# –°–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
used_labels = []

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
pd.set_option('display.precision', 2)
plt.style.use('default')

print("üöÄ –û–ë–õ–ï–ì–ß–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í–°–ö–ò–• –¢–†–ê–ù–ó–ê–ö–¶–ò–ô")
print("=" * 55)
print("üéØ –¶–µ–ª—å: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
print("‚ö° –ü–æ–¥—Ö–æ–¥: –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ + –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")

# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
print("\nüìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")


data_path = os.path.join(os.path.dirname(__file__), '..', 'data')
data_path = os.path.abspath(data_path)
parquet_files = []

if os.path.exists(data_path):
    for filename in os.listdir(data_path):
        if filename.endswith('.parquet'):
            parquet_files.append(os.path.join(data_path, filename))
            print(f"  üìÅ –ù–∞–π–¥–µ–Ω: {filename}")
else:
    print(f"‚ùå –ü–∞–ø–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_path}")
    exit()

df = None
if parquet_files:
    file_path = parquet_files[0]
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º: {file_path}")
    try:
        df = pd.read_parquet(file_path)
        print(
            f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape[0]:,} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {df['card_id'].nunique():,}")
        memory_usage = df.memory_usage(deep=True).sum() / 1024**3
        print(f"üíæ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {memory_usage:.1f} GB")
        if memory_usage > 8:
            print("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ - –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä–∫—É")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        df = None
else:
    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ parquet-—Ñ–∞–π–ª–∞")
    exit()

if df is None:
    print("üö´ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –∞–Ω–∞–ª–∏–∑")
    exit()

# 2. –ë–´–°–¢–†–ê–Ø –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•
print("\nüßπ –®–∞–≥ 2: –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

original_size = len(df)
df = df[df['transaction_amount_kzt'] > 0]
df['transaction_timestamp'] = pd.to_datetime(
    df['transaction_timestamp'], errors='coerce')
df = df[df['transaction_timestamp'].notna()]
print(f"–û—á–∏—Å—Ç–∫–∞: {original_size:,} ‚Üí {len(df):,} –∑–∞–ø–∏—Å–µ–π")

df['hour'] = df['transaction_timestamp'].dt.hour
df['day_of_week'] = df['transaction_timestamp'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# 3. –£–ú–ù–ê–Ø –í–´–ë–û–†–ö–ê –ö–õ–ò–ï–ù–¢–û–í
print("\nüéØ –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏...")

MAX_CLIENTS = 25000
unique_clients_total = df['card_id'].nunique()
print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {unique_clients_total:,}")

if unique_clients_total > MAX_CLIENTS:
    print(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–µ–º –≤—ã–±–æ—Ä–∫—É –∏–∑ {MAX_CLIENTS:,}")
    client_activity = df.groupby('card_id').agg({
        'transaction_amount_kzt': ['count', 'sum'],
        'transaction_timestamp': ['min', 'max']
    })
    client_activity.columns = ['txn_count',
                               'total_amount', 'first_txn', 'last_txn']
    client_activity['activity_days'] = (
        client_activity['last_txn'] - client_activity['first_txn']).dt.days + 1
    client_activity['activity_level'] = pd.cut(
        client_activity['txn_count'],
        bins=[0, 10, 50, 200, float('inf')],
        labels=['Low', 'Medium', 'High', 'VeryHigh']
    )
    sample_clients = []
    for level in ['Low', 'Medium', 'High', 'VeryHigh']:
        level_clients = client_activity[client_activity['activity_level'] == level].index
        sample_size = min(MAX_CLIENTS // 4, len(level_clients))
        if sample_size > 0:
            sample = np.random.choice(
                level_clients, sample_size, replace=False)
            sample_clients.extend(sample)
    remaining = MAX_CLIENTS - len(sample_clients)
    if remaining > 0:
        all_other = client_activity.index.difference(sample_clients)
        if len(all_other) > 0:
            additional = np.random.choice(all_other, min(
                remaining, len(all_other)), replace=False)
            sample_clients.extend(additional)
    df = df[df['card_id'].isin(sample_clients)]
    print(
        f"‚úÖ –í—ã–±–æ—Ä–∫–∞: {len(sample_clients):,} –∫–ª–∏–µ–Ω—Ç–æ–≤, {len(df):,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    del client_activity
    gc.collect()

# 4. –°–û–ó–î–ê–ù–ò–ï –ö–õ–Æ–ß–ï–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
print("\nüîß –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤...")

# –û—Ç–ª–∞–¥–∫–∞: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("üìã –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö:", df.columns.tolist())
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ MCC-–∫–æ–¥—ã:",
      df['merchant_mcc'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:",
      df['transaction_type'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–ª—é—Ç—ã:",
      df['transaction_currency'].value_counts(dropna=False).head(10))

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è merchant_mcc –≤ —Å—Ç—Ä–æ–∫–∏
df['merchant_mcc'] = df['merchant_mcc'].astype(str)

# –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
print("  üìä –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏...")
basic_features = df.groupby('card_id').agg({
    'transaction_amount_kzt': ['sum', 'mean', 'std', 'count', 'median'],
    'transaction_timestamp': ['min', 'max'],
    'merchant_id': 'nunique',
    'merchant_city': 'nunique',
    'acquirer_country_iso': lambda x: (x != 'KAZ').any()
}).reset_index()
basic_features.columns = ['card_id', 'total_amount', 'avg_amount', 'std_amount',
                          'transaction_count', 'median_amount', 'first_transaction',
                          'last_transaction', 'unique_merchants', 'unique_cities', 'has_foreign_txn']

# –ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç
valid_currencies = ['TRY', 'CNY', 'AED', 'AMD',
                    'BYN', 'KGS', 'UZS', 'USD', 'GEL', 'EUR']
currency_features = df[df['transaction_currency'].isin(valid_currencies)].groupby('card_id').agg({
    'transaction_currency': 'nunique'
}).reset_index()
currency_features.columns = ['card_id', 'unique_currencies']
basic_features = basic_features.merge(
    currency_features, on='card_id', how='left')
basic_features['unique_currencies'] = basic_features['unique_currencies'].fillna(
    0).astype(float)

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
print("  ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...")
time_features = df.groupby('card_id').agg({
    'hour': 'mean',
    'is_weekend': 'mean',
    'day_of_week': lambda x: x.mode().iloc[0] if len(x) > 0 else 0
}).reset_index()
time_features.columns = ['card_id', 'avg_hour',
                         'weekend_ratio', 'preferred_day']

# –†–∞—Å—á–µ—Ç —Ç—Ä–∞—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
print("  üè™ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—ã...")
client_features = basic_features.merge(time_features, on='card_id', how='left')

for category, mcc_list in categories.items():
    filtered_df = df[df['merchant_mcc'].isin([str(m) for m in mcc_list])]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {category}: {len(filtered_df)}")
    category_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    category_spending.columns = [
        'card_id', f'{category}_spending_amount', f'{category}_transaction_count']
    client_features = client_features.merge(
        category_spending, on='card_id', how='left')

for ttype, type_list in transaction_types.items():
    filtered_df = df[df['transaction_type'].isin(type_list)]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {ttype}: {len(filtered_df)}")
    type_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    type_spending.columns = [
        'card_id', f'{ttype}_spending_amount', f'{ttype}_transaction_count']
    client_features = client_features.merge(
        type_spending, on='card_id', how='left')

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
category_columns = []
for category in categories.keys():
    category_columns.extend(
        [f'{category}_spending_amount', f'{category}_transaction_count'])
for ttype in transaction_types.keys():
    category_columns.extend(
        [f'{ttype}_spending_amount', f'{ttype}_transaction_count'])
client_features[category_columns] = client_features[category_columns].fillna(0)

# –†–∞—Å—á–µ—Ç –¥–æ–ª–µ–π
ratio_columns = []
for category in categories.keys():
    client_features[f'{category}_spending_ratio'] = client_features[f'{category}_spending_amount'] / \
        client_features['total_amount']
    client_features[f'{category}_transaction_ratio'] = client_features[f'{category}_transaction_count'] / \
        client_features['transaction_count']
    ratio_columns.extend(
        [f'{category}_spending_ratio', f'{category}_transaction_ratio'])
for ttype in transaction_types.keys():
    client_features[f'{ttype}_spending_ratio'] = client_features[f'{ttype}_spending_amount'] / \
        client_features['total_amount']
    client_features[f'{ttype}_transaction_ratio'] = client_features[f'{ttype}_transaction_count'] / \
        client_features['transaction_count']
    ratio_columns.extend(
        [f'{ttype}_spending_ratio', f'{ttype}_transaction_ratio'])

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
client_features[ratio_columns] = client_features[ratio_columns].replace(
    [np.inf, -np.inf], 0).fillna(0)

# –î—Ä—É–≥–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
client_features['activity_days'] = (
    client_features['last_transaction'] - client_features['first_transaction']).dt.days + 1
client_features['avg_daily_transactions'] = client_features['transaction_count'] / \
    client_features['activity_days']
client_features['coefficient_variation'] = client_features['std_amount'] / \
    client_features['avg_amount']
client_features['avg_monthly_amount'] = client_features['total_amount'] / \
    (client_features['activity_days'] / 30)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
client_features = client_features.fillna(0)
client_features['coefficient_variation'] = client_features['coefficient_variation'].replace([
                                                                                            np.inf, -np.inf], 0)
numeric_cols = client_features.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    if col != 'card_id':
        client_features[col] = pd.to_numeric(
            client_features[col], errors='coerce').fillna(0).astype(float)

print("‚úÖ –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ float64")
del df
gc.collect()
print(
    f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(client_features.columns)-1} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(client_features):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")

# 5. –ü–û–î–ì–û–¢–û–í–ö–ê –ö –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò
print("\n‚öôÔ∏è –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")

# –î–æ–±–∞–≤–ª—è–µ–º transaction_count –∏ total_amount –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏
key_features = [f'{cat}_spending_ratio' for cat in categories.keys()] + \
               [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()] + \
               ['has_foreign_txn', 'unique_currencies',
                   'transaction_count', 'total_amount']
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(key_features)} –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {key_features}")

# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
feature_weights = {
    'auto_spending_ratio': 3.0,
    'cosmetic_spending_ratio': 2.0,
    'fashion_spending_ratio': 2.0,
    'beauty_salons_spending_ratio': 2.0,
    'construction_spending_ratio': 2.5,
    'book_and_sports_spending_ratio': 2.0,
    'tax_payment_spending_ratio': 1.5,
    'travel_spending_ratio': 2.0,
    'incoming_transfer_spending_ratio': 2.0,
    'outgoing_transfer_spending_ratio': 2.0,
    'ecom_spending_ratio': 2.5,
    'pos_spending_ratio': 2.0,
    'cash_withdrawal_spending_ratio': 2.5,
    'salary_spending_ratio': 1.5,
    'has_foreign_txn': 1.5,
    'unique_currencies': 2.5,
    'transaction_count': 2.0,  # –ù–æ–≤—ã–π –≤–µ—Å –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    'total_amount': 2.0        # –ù–æ–≤—ã–π –≤–µ—Å –¥–ª—è –æ–±—ä—ë–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
}

X = client_features[key_features].copy()
for feature, weight in feature_weights.items():
    if feature in X.columns:
        X[feature] = X[feature] * weight

for col in X.columns:
    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)

print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤...")
for col in X.columns:
    Q99 = float(X[col].quantile(0.99))
    Q01 = float(X[col].quantile(0.01))
    X.loc[X[col] > Q99, col] = Q99
    X.loc[X[col] < Q01, col] = Q01

X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

print("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤...")
for col in X.columns:
    if X[col].dtype != 'float64':
        print(f"  –ò—Å–ø—Ä–∞–≤–ª—è–µ–º {col}: {X[col].dtype} ‚Üí float64")
        X[col] = X[col].astype(float)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

# 6. –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø
print("\nüéØ –®–∞–≥ 6: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è...")

n_clients = len(X_scaled)
print(f"–ö–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {n_clients:,}")

K_range = range(2, 11)  # –§–∏–∫—Å–∏—Ä—É–µ–º 19 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∞—à–∏—Ö –ø—Ä–æ—Ñ–∏–ª—è—Ö
inertias = []
silhouette_scores = []

for k in K_range:
    print(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º K={k}...", end="")
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=5, max_iter=100)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    if k == 1:
        silhouette_scores.append(float('nan'))
        print(" —Å–∏–ª—É—ç—Ç: N/A (k=1)")
        continue
    if n_clients > 5000:
        sample_size = 3000
        sample_indices = np.random.choice(
            n_clients, sample_size, replace=False)
        sil_score = silhouette_score(
            X_scaled[sample_indices], labels[sample_indices])
    else:
        sil_score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(sil_score)
    print(f" —Å–∏–ª—É—ç—Ç: {sil_score:.3f}")

optimal_k = K_range[np.argmax(silhouette_scores)]
best_silhouette = max(silhouette_scores)
print(f"\n‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ K: {optimal_k} (—Å–∏–ª—É—ç—Ç: {best_silhouette:.3f})")

print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å K={optimal_k}...")
final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
final_labels = final_kmeans.fit_predict(X_scaled)
client_features['cluster'] = final_labels
print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

# 7. –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüìà –®–∞–≥ 7: –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
cluster_distribution = pd.Series(final_labels).value_counts().sort_index()
for cluster_id, count in cluster_distribution.items():
    percentage = count / len(client_features) * 100
    print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count:,} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")

print(f"\nüí° –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
key_profile_features = ['total_amount', 'transaction_count', 'unique_merchants', 'unique_cities',
                        'weekend_ratio', 'avg_hour', 'has_foreign_txn', 'unique_currencies'] + \
    [f'{cat}_spending_ratio' for cat in categories.keys()] + \
    [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]


def interpret_cluster(cluster_data, used_labels, cluster_id):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤
    """
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    transaction_count = cluster_data['transaction_count'].mean()
    total_amount = cluster_data['total_amount'].mean(
    ) / 1_000_000  # –í –º–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–µ–Ω–≥–µ
    unique_merchants = cluster_data['unique_merchants'].mean()
    unique_cities = cluster_data['unique_cities'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    avg_hour = cluster_data['avg_hour'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean(
    ) if 'unique_currencies' in cluster_data else 0
    foreign_txn_ratio = cluster_data['has_foreign_txn'].mean(
    ) if 'has_foreign_txn' in cluster_data else 0

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ç—Ä–∞—Ç—ã (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è)
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean()
              for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean(
    ) for ttype in transaction_types.keys()})

    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"\nüîç –ö–ª–∞—Å—Ç–µ—Ä {cluster_id} ({len(cluster_data)} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    print(f"  total_amount: {total_amount:.1f}M‚Ç∏")
    print(f"  transaction_count: {transaction_count:.0f}")
    print(f"  unique_currencies: {unique_currencies:.1f}")
    print(f"  foreign_txn_ratio: {foreign_txn_ratio:.3f}")
    print(f"  unique_merchants: {unique_merchants:.1f}")
    print(f"  auto_spending_ratio: {ratios.get('auto', 0):.3f}")
    print(f"  ecom_spending_ratio: {ratios.get('ecom', 0):.3f}")
    print(f"  pos_spending_ratio: {ratios.get('pos', 0):.3f}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

    # –£—Ä–æ–≤–Ω–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    LOW_ACTIVITY = 500        # –ú–∞–ª–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    MEDIUM_ACTIVITY = 2000    # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    HIGH_ACTIVITY = 5000      # –í—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

    # –£—Ä–æ–≤–Ω–∏ –ø–æ —Å—É–º–º–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (–≤ –º–ª–Ω —Ç–µ–Ω–≥–µ)
    LOW_AMOUNT = 5           # –ù–µ–±–æ–ª—å—à–∏–µ —Å—É–º–º—ã
    MEDIUM_AMOUNT = 50       # –°—Ä–µ–¥–Ω–∏–µ —Å—É–º–º—ã
    HIGH_AMOUNT = 200        # –í—ã—Å–æ–∫–∏–µ —Å—É–º–º—ã
    PREMIUM_AMOUNT = 500     # –ü—Ä–µ–º–∏—É–º —Å—É–º–º—ã
    ELITE_AMOUNT = 1000      # –≠–ª–∏—Ç–Ω—ã–µ —Å—É–º–º—ã

    # –ì–ª–æ–±–∞–ª—å–Ω–æ—Å—Ç—å (–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏)
    GLOBAL_CURRENCIES = 2    # –ú–∏–Ω–∏–º—É–º –≤–∞–ª—é—Ç –¥–ª—è "–≥–ª–æ–±–∞–ª—å–Ω–æ—Å—Ç–∏"
    GLOBAL_FOREIGN_RATIO = 0.3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –∑–∞—Ä—É–±–µ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

    # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    AUTO_THRESHOLD = 0.15    # –ü–æ—Ä–æ–≥–æ–≤–∞—è –¥–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –∞–≤—Ç–æ
    SHOPPING_ECOM_THRESHOLD = 0.3  # –ü–æ—Ä–æ–≥–æ–≤–∞—è –¥–æ–ª—è –æ–Ω–ª–∞–π–Ω-—à–æ–ø–∏–Ω–≥–∞
    SHOPPING_POS_THRESHOLD = 0.4   # –ü–æ—Ä–æ–≥–æ–≤–∞—è –¥–æ–ª—è –æ—Ñ–ª–∞–π–Ω-—à–æ–ø–∏–Ω–≥–∞

    # –õ–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞

    # 1. –≠–ª–∏—Ç–Ω—ã–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏
    # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ —Å—É–º–º—ã + –º–Ω–æ–≥–æ –≤–∞–ª—é—Ç + –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è –∑–∞—Ä—É–±–µ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    if (total_amount >= ELITE_AMOUNT and
        unique_currencies >= GLOBAL_CURRENCIES and
            foreign_txn_ratio >= GLOBAL_FOREIGN_RATIO):
        return "–≠–ª–∏—Ç–Ω—ã–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏"

    # 2. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏
    # –í—ã—Å–æ–∫–∏–µ —Å—É–º–º—ã + –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –Ω–æ –Ω–µ —ç–ª–∏—Ç–Ω—ã–µ
    elif (total_amount >= HIGH_AMOUNT and
          (unique_currencies >= GLOBAL_CURRENCIES or foreign_txn_ratio >= GLOBAL_FOREIGN_RATIO)):
        return "–ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏"

    # 3. –≠–ª–∏—Ç–Ω—ã–µ —à–æ–ø–æ–≥–æ–ª–∏–∫–∏
    # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ —Å—É–º–º—ã + –≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –º–Ω–æ–≥–æ —à–æ–ø–∏–Ω–≥–∞, –Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ
    elif (total_amount >= ELITE_AMOUNT and
          transaction_count >= HIGH_ACTIVITY and
          (ratios.get('ecom', 0) >= SHOPPING_ECOM_THRESHOLD or
           ratios.get('pos', 0) >= SHOPPING_POS_THRESHOLD) and
          unique_currencies < GLOBAL_CURRENCIES):
        return "–≠–ª–∏—Ç–Ω—ã–µ —à–æ–ø–æ–≥–æ–ª–∏–∫–∏"

    # 4. –ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–º–∏—É–º-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    # –í—ã—Å–æ–∫–∏–µ —Å—É–º–º—ã + –≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–æ –Ω–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
    elif (total_amount >= PREMIUM_AMOUNT and transaction_count >= HIGH_ACTIVITY):
        return "–ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–º–∏—É–º-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"

    # 5. –ê–∫—Ç–∏–≤–Ω—ã–µ –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª–∏
    # –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –∞–≤—Ç–æ + –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    elif (ratios.get('auto', 0) >= AUTO_THRESHOLD and
          transaction_count >= MEDIUM_ACTIVITY and
          total_amount >= MEDIUM_AMOUNT):
        return "–ê–∫—Ç–∏–≤–Ω—ã–µ –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª–∏"

    # 6. –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —à–æ–ø–æ–≥–æ–ª–∏–∫–∏
    # –°—Ä–µ–¥–Ω–∏–µ —Å—É–º–º—ã + –∞–∫—Ç–∏–≤–Ω—ã–π —à–æ–ø–∏–Ω–≥ + –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    elif (total_amount >= MEDIUM_AMOUNT and
          transaction_count >= MEDIUM_ACTIVITY and
          (ratios.get('ecom', 0) >= SHOPPING_ECOM_THRESHOLD or
           ratios.get('pos', 0) >= SHOPPING_POS_THRESHOLD) and
          unique_currencies < GLOBAL_CURRENCIES):
        return "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —à–æ–ø–æ–≥–æ–ª–∏–∫–∏"

    # 7. –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏
    # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + —Å—Ä–µ–¥–Ω–∏–µ —Å—É–º–º—ã + –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    elif (transaction_count >= MEDIUM_ACTIVITY and
          MEDIUM_AMOUNT <= total_amount < PREMIUM_AMOUNT and
          unique_currencies < GLOBAL_CURRENCIES):
        return "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏"

    # 8. –≠–∫–æ–Ω–æ–º–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    # –ù–∏–∑–∫–∏–µ —Å—É–º–º—ã + –Ω–∏–∑–∫–∞—è-—Å—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    elif (total_amount < MEDIUM_AMOUNT and
          LOW_ACTIVITY <= transaction_count < HIGH_ACTIVITY and
          unique_currencies < GLOBAL_CURRENCIES):
        return "–≠–∫–æ–Ω–æ–º–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"

    # 9. –ü–∞—Å—Å–∏–≤–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –Ω–∏–∑–∫–∏–µ —Å—É–º–º—ã + –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    elif (transaction_count >= LOW_ACTIVITY and
          total_amount < LOW_AMOUNT and
          unique_currencies < GLOBAL_CURRENCIES):
        return "–ü–∞—Å—Å–∏–≤–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"

    # 10. –°–ø—è—â–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–µ —Å—É–º–º—ã
    elif (transaction_count < LOW_ACTIVITY and total_amount < LOW_AMOUNT):
        return "–°–ø—è—â–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"

    # –ï—Å–ª–∏ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –Ω–∏ –ø–æ–¥ –æ–¥–∏–Ω –ø—Ä–æ—Ñ–∏–ª—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
    else:
        return f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}"


# –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–∏–º –ª–æ–≥–∏–∫—É –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
def get_cluster_priority(cluster_data):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    total_amount = cluster_data['total_amount'].mean() / 1_000_000
    transaction_count = cluster_data['transaction_count'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean()
    foreign_txn_ratio = cluster_data['has_foreign_txn'].mean()

    # –≠–ª–∏—Ç–Ω—ã–µ –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –∏–º–µ—é—Ç –Ω–∞–∏–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    elite_score = min(total_amount / 1000, 1.0) * \
        100  # –¥–æ 100 –±–∞–ª–ª–æ–≤ –∑–∞ —ç–ª–∏—Ç–Ω–æ—Å—Ç—å
    global_score = (unique_currencies * 10) + \
        (foreign_txn_ratio * 50)  # –¥–æ 60+ –±–∞–ª–ª–æ–≤ –∑–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ—Å—Ç—å
    activity_score = min(transaction_count / 10000, 1.0) * \
        50  # –¥–æ 50 –±–∞–ª–ª–æ–≤ –∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

    total_priority = elite_score + global_score + activity_score
    return total_priority


# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –∫–æ–¥–µ
print("üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_priorities = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    priority = get_cluster_priority(cluster_data)
    cluster_priorities.append((cluster_id, priority))

# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–æ—Ç –≤—ã—Å–æ–∫–æ–≥–æ –∫ –Ω–∏–∑–∫–æ–º—É)
cluster_priorities.sort(key=lambda x: x[1], reverse=True)

# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∫ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É
used_labels = []  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
cluster_labels = []

for cluster_id, priority in cluster_priorities:
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    cluster_label = interpret_cluster(cluster_data, used_labels, cluster_id)
    cluster_labels.append((cluster_id, cluster_label))

    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Ç–µ—Ä–µ
    size = len(cluster_data)
    print(f"\nüîπ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    print(f"  ‚Ä¢ –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞: {cluster_label}")
    print(f"  ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority:.1f}")

    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_avg = cluster_data['total_amount'].mean()
    txn_avg = cluster_data['transaction_count'].mean()
    merchants_avg = cluster_data['unique_merchants'].mean()
    cities_avg = cluster_data['unique_cities'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    foreign_txn = cluster_data['has_foreign_txn'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean()

    print(f"  ‚Ä¢ –û–±—â–∞—è —Å—É–º–º–∞: {total_avg:,.0f} —Ç–µ–Ω–≥–µ")
    print(f"  ‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {txn_avg:.0f}")
    print(f"  ‚Ä¢ –ü—Ä–æ–¥–∞–≤—Ü–æ–≤: {merchants_avg:.1f}")
    print(f"  ‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤: {cities_avg:.1f}")
    print(f"  ‚Ä¢ –î–æ–ª—è –∑–∞–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {foreign_txn:.1%}")
    print(f"  ‚Ä¢ Weekend –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {weekend_ratio:.1%}")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç: {unique_currencies:.1f}")

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ç—Ä–∞—Ç—ã
    for cat in categories.keys():
        ratio = cluster_data[f'{cat}_spending_ratio'].mean()
        if ratio > 0.05:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {cat}: {ratio:.1%}")

    for ttype in transaction_types.keys():
        ratio = cluster_data[f'{ttype}_spending_ratio'].mean()
        if ratio > 0.1:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —Ç–∏–ø—ã
            print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {ttype}: {ratio:.1%}")


# –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_priorities = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    unique_currencies = cluster_data['unique_currencies'].mean()
    total_amount = cluster_data['total_amount'].mean() / 1_000_000
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean()
              for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean(
    ) for ttype in transaction_types.keys()})
    style_spending_ratio = (ratios.get(
        'cosmetic', 0) + ratios.get('fashion', 0) + ratios.get('beauty_salons', 0))
    active_ratios = {
        'auto': ratios.get('auto', 0),
        'style': style_spending_ratio,
        'construction': ratios.get('construction', 0),
        'book_and_sports': ratios.get('book_and_sports', 0),
        'ecom': ratios.get('ecom', 0),
        'pos': ratios.get('pos', 0),
        'cash_withdrawal': ratios.get('cash_withdrawal', 0),
        'salary': ratios.get('salary', 0)

    }
    max_ratio = max(active_ratios.values(), default=0)
    priority = max(unique_currencies, total_amount, max_ratio)
    cluster_priorities.append((cluster_id, priority))

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
cluster_priorities.sort(key=lambda x: x[1], reverse=True)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
for cluster_id, priority in cluster_priorities:
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    size = len(cluster_data)
    print(f"\nüîπ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    cluster_label = interpret_cluster(cluster_data, used_labels, cluster_id)
    print(f"  ‚Ä¢ –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞: {cluster_label}")
    total_avg = cluster_data['total_amount'].mean()
    txn_avg = cluster_data['transaction_count'].mean()
    merchants_avg = cluster_data['unique_merchants'].mean()
    cities_avg = cluster_data['unique_cities'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    foreign_txn = cluster_data['has_foreign_txn'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean()
    print(f"  ‚Ä¢ –û–±—â–∞—è —Å—É–º–º–∞: {total_avg:,.0f} —Ç–µ–Ω–≥–µ")
    print(f"  ‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {txn_avg:.0f}")
    print(f"  ‚Ä¢ –ü—Ä–æ–¥–∞–≤—Ü–æ–≤: {merchants_avg:.1f}")
    print(f"  ‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤: {cities_avg:.1f}")
    print(f"  ‚Ä¢ –î–æ–ª—è –∑–∞–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {foreign_txn:.1%}")
    print(f"  ‚Ä¢ Weekend –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {weekend_ratio:.1%}")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç: {unique_currencies:.1f}")
    for cat in categories.keys():
        print(
            f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {cat}: {cluster_data[f'{cat}_spending_ratio'].mean():.1%}")
    for ttype in transaction_types.keys():
        print(
            f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {ttype}: {cluster_data[f'{ttype}_spending_ratio'].mean():.1%}")

# 8. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\nüé® –®–∞–≥ 8: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

# –ü—Ä–∏–º–µ–Ω—è–µ–º PCA —Å 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X_scaled)

# –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã
used_labels = []
cluster_labels = []
cluster_metrics = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    label = interpret_cluster(cluster_data, used_labels, cluster_id)
    avg_total_amount = cluster_data['total_amount'].mean() / 1_000_000
    avg_transaction_count = cluster_data['transaction_count'].mean()
    cluster_labels.append((cluster_id, label))
    cluster_metrics.append(
        (cluster_id, avg_total_amount, avg_transaction_count))

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
total_amounts = client_features['total_amount'].values
transaction_counts = client_features['transaction_count'].values
amount_min, amount_max = total_amounts.min(), total_amounts.max()
if amount_max > amount_min:
    sizes = 10 + 90 * (total_amounts - amount_min) / (amount_max - amount_min)
else:
    sizes = np.full_like(total_amounts, 50.0)
count_min, count_max = transaction_counts.min(), transaction_counts.max()
if count_max > count_min:
    alphas = 0.3 + 0.5 * (transaction_counts - count_min) / \
        (count_max - count_min)
else:
    alphas = np.full_like(transaction_counts, 0.5)

# 3D-–≥—Ä–∞—Ñ–∏–∫
fig = plt.figure(figsize=(14, 10))
ax = fig.add_subplot(111, projection='3d')
colors = plt.cm.tab20(np.linspace(0, 1, optimal_k))
for i in range(optimal_k):
    mask = final_labels == i
    cluster_label = next(
        (label for cid, label in cluster_labels if cid == i), f"–ö–ª–∞—Å—Ç–µ—Ä {i}")
    avg_amount = next((amt for cid, amt, _ in cluster_metrics if cid == i), 0)
    avg_count = next((cnt for cid, _, cnt in cluster_metrics if cid == i), 0)
    legend_label = f"{cluster_label} (–°—É–º–º–∞: {avg_amount:.1f}M‚Ç∏, –¢—Ä–∞–Ω–∑: {avg_count:.0f})"
    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],
               c=[colors[i]], label=legend_label,
               s=sizes[mask], alpha=float(np.mean(alphas[mask])))

ax.set_title('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ 3D-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ PCA —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π')
ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
plt.tight_layout()
plt.savefig('pca_3d_clusters_with_metrics.png', bbox_inches='tight', dpi=300)
print("‚úÖ 3D-–≥—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'pca_3d_clusters_with_metrics.png'")

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤', fontsize=14)
cluster_sizes = [sum(final_labels == i) for i in range(optimal_k)]
axes[0, 0].bar(range(optimal_k), cluster_sizes, color=colors)
axes[0, 0].set_title('–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
axes[0, 0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤')
cluster_travel = client_features.groupby(
    'cluster')['travel_spending_ratio'].mean()
axes[0, 1].bar(cluster_travel.index, cluster_travel.values, color=colors)
axes[0, 1].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è')
axes[0, 1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0, 1].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')
cluster_auto = client_features.groupby('cluster')['auto_spending_ratio'].mean()
axes[1, 0].bar(cluster_auto.index, cluster_auto.values, color=colors)
axes[1, 0].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å—ã')
axes[1, 0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1, 0].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')
axes[1, 1].axis('off')
plt.tight_layout()
plt.savefig('cluster_analysis.png', bbox_inches='tight', dpi=300)
print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'cluster_analysis.png'")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(K_range, inertias, 'bo-')
ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax1.set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
ax1.grid(True)
ax2.plot(K_range, silhouette_scores, 'ro-')
ax2.set_title('–°–∏–ª—É—ç—Ç –∞–Ω–∞–ª–∏–∑')
ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax2.set_ylabel('–°–∏–ª—É—ç—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7)
ax2.grid(True)
plt.tight_layout()
plt.savefig('elbow_silhouette.png', bbox_inches='tight', dpi=300)
print("‚úÖ –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è –∏ —Å–∏–ª—É—ç—Ç-–∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ 'elbow_silhouette.png'")
plt.show()

# 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüíæ –®–∞–≥ 9: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

output_columns = ['card_id', 'total_amount', 'transaction_count', 'unique_merchants',
                  'unique_cities', 'weekend_ratio', 'avg_hour', 'has_foreign_txn',
                  'unique_currencies', 'cluster'] + \
    [f'{cat}_spending_ratio' for cat in categories.keys()] + \
    [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]
final_results = client_features[output_columns].copy()
final_results['cluster_label'] = final_results['cluster'].apply(
    lambda x: interpret_cluster(
        client_features[client_features['cluster'] == x], [], x)
)
final_results.to_csv('client_segments.csv', index=False)
print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'client_segments.csv'")

used_labels_profiles = []
cluster_profiles = client_features.groupby(
    'cluster')[key_profile_features].agg(['mean', 'median']).round(2)
clients_count = client_features.groupby('cluster').size()
cluster_profiles['clients_count'] = clients_count

cluster_profiles.to_csv('cluster_profiles_summary.csv')
print("‚úÖ –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'cluster_profiles_summary.csv'")
