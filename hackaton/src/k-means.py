import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from mpl_toolkits.mplot3d import Axes3D
import warnings
import os
import gc
warnings.filterwarnings('ignore')

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
categories = {
    'auto': [5541, 5542, 7513, 7531, 5599],
    'cosmetic': [5999, 7298, 5945, 5977],
    'fashion': [5651, 5699, 5691],
    'beauty_salons': [7230],
    'construction': [5311, 5310, 5122, 5712, 5200, 5211, 5722, 5732, 5734],
    'book_and_sports': [5941, 5942],
    'tax_payment': [9311],
    'travel': [3000, 3010, 3050, 3500, 7011]
}

transaction_types = {
    'incoming_transfer': ['P2P_IN'],
    'outgoing_transfer': ['P2P_OUT'],
    'ecom': ['ECOM'],
    'pos': ['POS'],
    'cash_withdrawal': ['ATM_WITHDRAWAL'],
    'salary': ['SALARY']
}

# –ü–æ—Ä–æ–≥ –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
min_currencies_travel = 3

# –°–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
used_labels = []

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
pd.set_option('display.precision', 2)
plt.style.use('default')

print("üöÄ –û–ë–õ–ï–ì–ß–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í–°–ö–ò–• –¢–†–ê–ù–ó–ê–ö–¶–ò–ô")
print("=" * 55)
print("üéØ –¶–µ–ª—å: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
print("‚ö° –ü–æ–¥—Ö–æ–¥: –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ + –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")

# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
print("\nüìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

data_path = r"C:\Users\ksyus\Desktop\Education\Owl-Decentra\hackaton\data"
parquet_files = []

if os.path.exists(data_path):
    for filename in os.listdir(data_path):
        if filename.endswith('.parquet'):
            parquet_files.append(os.path.join(data_path, filename))
            print(f"  üìÅ –ù–∞–π–¥–µ–Ω: {filename}")
else:
    print(f"‚ùå –ü–∞–ø–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_path}")
    exit()

df = None
if parquet_files:
    file_path = parquet_files[0]
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º: {file_path}")
    try:
        df = pd.read_parquet(file_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape[0]:,} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {df['card_id'].nunique():,}")
        memory_usage = df.memory_usage(deep=True).sum() / 1024**3
        print(f"üíæ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {memory_usage:.1f} GB")
        if memory_usage > 8:
            print("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ - –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä–∫—É")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        df = None
else:
    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ parquet-—Ñ–∞–π–ª–∞")
    exit()

if df is None:
    print("üö´ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –∞–Ω–∞–ª–∏–∑")
    exit()

# 2. –ë–´–°–¢–†–ê–Ø –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•
print("\nüßπ –®–∞–≥ 2: –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

original_size = len(df)
df = df[df['transaction_amount_kzt'] > 0]
df['transaction_timestamp'] = pd.to_datetime(df['transaction_timestamp'], errors='coerce')
df = df[df['transaction_timestamp'].notna()]
print(f"–û—á–∏—Å—Ç–∫–∞: {original_size:,} ‚Üí {len(df):,} –∑–∞–ø–∏—Å–µ–π")

df['hour'] = df['transaction_timestamp'].dt.hour
df['day_of_week'] = df['transaction_timestamp'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# 3. –£–ú–ù–ê–Ø –í–´–ë–û–†–ö–ê –ö–õ–ò–ï–ù–¢–û–í
print("\nüéØ –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏...")

MAX_CLIENTS = 25000
unique_clients_total = df['card_id'].nunique()
print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {unique_clients_total:,}")

if unique_clients_total > MAX_CLIENTS:
    print(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–µ–º –≤—ã–±–æ—Ä–∫—É –∏–∑ {MAX_CLIENTS:,}")
    client_activity = df.groupby('card_id').agg({
        'transaction_amount_kzt': ['count', 'sum'],
        'transaction_timestamp': ['min', 'max']
    })
    client_activity.columns = ['txn_count', 'total_amount', 'first_txn', 'last_txn']
    client_activity['activity_days'] = (client_activity['last_txn'] - client_activity['first_txn']).dt.days + 1
    client_activity['activity_level'] = pd.cut(
        client_activity['txn_count'],
        bins=[0, 10, 50, 200, float('inf')],
        labels=['Low', 'Medium', 'High', 'VeryHigh']
    )
    sample_clients = []
    for level in ['Low', 'Medium', 'High', 'VeryHigh']:
        level_clients = client_activity[client_activity['activity_level'] == level].index
        sample_size = min(MAX_CLIENTS // 4, len(level_clients))
        if sample_size > 0:
            sample = np.random.choice(level_clients, sample_size, replace=False)
            sample_clients.extend(sample)
    remaining = MAX_CLIENTS - len(sample_clients)
    if remaining > 0:
        all_other = client_activity.index.difference(sample_clients)
        if len(all_other) > 0:
            additional = np.random.choice(all_other, min(remaining, len(all_other)), replace=False)
            sample_clients.extend(additional)
    df = df[df['card_id'].isin(sample_clients)]
    print(f"‚úÖ –í—ã–±–æ—Ä–∫–∞: {len(sample_clients):,} –∫–ª–∏–µ–Ω—Ç–æ–≤, {len(df):,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    del client_activity
    gc.collect()

# 4. –°–û–ó–î–ê–ù–ò–ï –ö–õ–Æ–ß–ï–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
print("\nüîß –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤...")

# –û—Ç–ª–∞–¥–∫–∞: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("üìã –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö:", df.columns.tolist())
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ MCC-–∫–æ–¥—ã:", df['merchant_mcc'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:", df['transaction_type'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–ª—é—Ç—ã:", df['transaction_currency'].value_counts(dropna=False).head(10))

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è merchant_mcc –≤ —Å—Ç—Ä–æ–∫–∏
df['merchant_mcc'] = df['merchant_mcc'].astype(str)

# –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
print("  üìä –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏...")
basic_features = df.groupby('card_id').agg({
    'transaction_amount_kzt': ['sum', 'mean', 'std', 'count', 'median'],
    'transaction_timestamp': ['min', 'max'],
    'merchant_id': 'nunique',
    'merchant_city': 'nunique',
    'acquirer_country_iso': lambda x: (x != 'KAZ').any()
}).reset_index()
basic_features.columns = ['card_id', 'total_amount', 'avg_amount', 'std_amount',
                         'transaction_count', 'median_amount', 'first_transaction',
                         'last_transaction', 'unique_merchants', 'unique_cities', 'has_foreign_txn']

# –ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç
valid_currencies = ['TRY', 'CNY', 'AED', 'AMD', 'BYN', 'KGS', 'UZS', 'USD', 'GEL', 'EUR']
currency_features = df[df['transaction_currency'].isin(valid_currencies)].groupby('card_id').agg({
    'transaction_currency': 'nunique'
}).reset_index()
currency_features.columns = ['card_id', 'unique_currencies']
basic_features = basic_features.merge(currency_features, on='card_id', how='left')
basic_features['unique_currencies'] = basic_features['unique_currencies'].fillna(0).astype(float)

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
print("  ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...")
time_features = df.groupby('card_id').agg({
    'hour': 'mean',
    'is_weekend': 'mean',
    'day_of_week': lambda x: x.mode().iloc[0] if len(x) > 0 else 0
}).reset_index()
time_features.columns = ['card_id', 'avg_hour', 'weekend_ratio', 'preferred_day']

# –†–∞—Å—á–µ—Ç —Ç—Ä–∞—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
print("  üè™ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—ã...")
client_features = basic_features.merge(time_features, on='card_id', how='left')

for category, mcc_list in categories.items():
    filtered_df = df[df['merchant_mcc'].isin([str(m) for m in mcc_list])]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {category}: {len(filtered_df)}")
    category_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    category_spending.columns = ['card_id', f'{category}_spending_amount', f'{category}_transaction_count']
    client_features = client_features.merge(category_spending, on='card_id', how='left')

for ttype, type_list in transaction_types.items():
    filtered_df = df[df['transaction_type'].isin(type_list)]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {ttype}: {len(filtered_df)}")
    type_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    type_spending.columns = ['card_id', f'{ttype}_spending_amount', f'{ttype}_transaction_count']
    client_features = client_features.merge(type_spending, on='card_id', how='left')

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
category_columns = []
for category in categories.keys():
    category_columns.extend([f'{category}_spending_amount', f'{category}_transaction_count'])
for ttype in transaction_types.keys():
    category_columns.extend([f'{ttype}_spending_amount', f'{ttype}_transaction_count'])
client_features[category_columns] = client_features[category_columns].fillna(0)

# –†–∞—Å—á–µ—Ç –¥–æ–ª–µ–π
ratio_columns = []
for category in categories.keys():
    client_features[f'{category}_spending_ratio'] = client_features[f'{category}_spending_amount'] / client_features['total_amount']
    client_features[f'{category}_transaction_ratio'] = client_features[f'{category}_transaction_count'] / client_features['transaction_count']
    ratio_columns.extend([f'{category}_spending_ratio', f'{category}_transaction_ratio'])
for ttype in transaction_types.keys():
    client_features[f'{ttype}_spending_ratio'] = client_features[f'{ttype}_spending_amount'] / client_features['total_amount']
    client_features[f'{ttype}_transaction_ratio'] = client_features[f'{ttype}_transaction_count'] / client_features['transaction_count']
    ratio_columns.extend([f'{ttype}_spending_ratio', f'{ttype}_transaction_ratio'])

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
client_features[ratio_columns] = client_features[ratio_columns].replace([np.inf, -np.inf], 0).fillna(0)

# –î—Ä—É–≥–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
client_features['activity_days'] = (client_features['last_transaction'] - client_features['first_transaction']).dt.days + 1
client_features['avg_daily_transactions'] = client_features['transaction_count'] / client_features['activity_days']
client_features['coefficient_variation'] = client_features['std_amount'] / client_features['avg_amount']
client_features['avg_monthly_amount'] = client_features['total_amount'] / (client_features['activity_days'] / 30)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
client_features = client_features.fillna(0)
client_features['coefficient_variation'] = client_features['coefficient_variation'].replace([np.inf, -np.inf], 0)
numeric_cols = client_features.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    if col != 'card_id':
        client_features[col] = pd.to_numeric(client_features[col], errors='coerce').fillna(0).astype(float)

print("‚úÖ –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ float64")
del df
gc.collect()
print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(client_features.columns)-1} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(client_features):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")

# 5. –ü–û–î–ì–û–¢–û–í–ö–ê –ö –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò
print("\n‚öôÔ∏è –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")

# –î–æ–±–∞–≤–ª—è–µ–º transaction_count –∏ total_amount –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏
key_features = [f'{cat}_spending_ratio' for cat in categories.keys()] + \
               [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()] + \
               ['has_foreign_txn', 'unique_currencies', 'transaction_count', 'total_amount']
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(key_features)} –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {key_features}")

# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
feature_weights = {
    'auto_spending_ratio': 3.0,
    'cosmetic_spending_ratio': 2.0,
    'fashion_spending_ratio': 2.0,
    'beauty_salons_spending_ratio': 2.0,
    'construction_spending_ratio': 2.5,
    'book_and_sports_spending_ratio': 2.0,
    'tax_payment_spending_ratio': 1.5,
    'travel_spending_ratio': 2.0,
    'incoming_transfer_spending_ratio': 2.0,
    'outgoing_transfer_spending_ratio': 2.0,
    'ecom_spending_ratio': 2.5,
    'pos_spending_ratio': 2.0,
    'cash_withdrawal_spending_ratio': 2.5,
    'salary_spending_ratio': 1.5,
    'has_foreign_txn': 1.5,
    'unique_currencies': 2.5,
    'transaction_count': 2.0,  # –ù–æ–≤—ã–π –≤–µ—Å –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    'total_amount': 2.0        # –ù–æ–≤—ã–π –≤–µ—Å –¥–ª—è –æ–±—ä—ë–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
}

X = client_features[key_features].copy()
for feature, weight in feature_weights.items():
    if feature in X.columns:
        X[feature] = X[feature] * weight

for col in X.columns:
    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)

print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤...")
for col in X.columns:
    Q99 = float(X[col].quantile(0.99))
    Q01 = float(X[col].quantile(0.01))
    X.loc[X[col] > Q99, col] = Q99
    X.loc[X[col] < Q01, col] = Q01

X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

print("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤...")
for col in X.columns:
    if X[col].dtype != 'float64':
        print(f"  –ò—Å–ø—Ä–∞–≤–ª—è–µ–º {col}: {X[col].dtype} ‚Üí float64")
        X[col] = X[col].astype(float)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

# 6. –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø
print("\nüéØ –®–∞–≥ 6: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è...")

n_clients = len(X_scaled)
print(f"–ö–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {n_clients:,}")

K_range = range(2, 11)  # –§–∏–∫—Å–∏—Ä—É–µ–º 19 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∞—à–∏—Ö –ø—Ä–æ—Ñ–∏–ª—è—Ö
inertias = []
silhouette_scores = []

for k in K_range:
    print(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º K={k}...", end="")
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=5, max_iter=100)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    if k == 1:
        silhouette_scores.append(float('nan'))
        print(" —Å–∏–ª—É—ç—Ç: N/A (k=1)")
        continue
    if n_clients > 5000:
        sample_size = 3000
        sample_indices = np.random.choice(n_clients, sample_size, replace=False)
        sil_score = silhouette_score(X_scaled[sample_indices], labels[sample_indices])
    else:
        sil_score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(sil_score)
    print(f" —Å–∏–ª—É—ç—Ç: {sil_score:.3f}")

optimal_k = K_range[np.argmax(silhouette_scores)]
best_silhouette = max(silhouette_scores)
print(f"\n‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ K: {optimal_k} (—Å–∏–ª—É—ç—Ç: {best_silhouette:.3f})")

print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å K={optimal_k}...")
final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
final_labels = final_kmeans.fit_predict(X_scaled)
client_features['cluster'] = final_labels
print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

# 7. –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüìà –®–∞–≥ 7: –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
cluster_distribution = pd.Series(final_labels).value_counts().sort_index()
for cluster_id, count in cluster_distribution.items():
    percentage = count / len(client_features) * 100
    print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count:,} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")

print(f"\nüí° –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
key_profile_features = ['total_amount', 'transaction_count', 'unique_merchants', 'unique_cities',
                       'weekend_ratio', 'avg_hour', 'has_foreign_txn', 'unique_currencies'] + \
                      [f'{cat}_spending_ratio' for cat in categories.keys()] + \
                      [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]

def interpret_cluster(cluster_data, used_labels, cluster_id):
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean() for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean() for ttype in transaction_types.keys()})
    transaction_count = cluster_data['transaction_count'].mean()
    total_amount = cluster_data['total_amount'].mean() / 1_000_000  # –í –º–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–µ–Ω–≥–µ
    unique_merchants = cluster_data['unique_merchants'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    avg_hour = cluster_data['avg_hour'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean() if 'unique_currencies' in cluster_data else 0
    foreign_txn_ratio = cluster_data['has_foreign_txn'].mean() if 'has_foreign_txn' in cluster_data else 0

    # –ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–µ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    category_threshold = 0.1
    fraud_threshold = 0.3
    min_transactions = 20
    max_merchants_fraud = 200
    ecom_threshold = 0.2
    style_threshold = 0.08
    auto_threshold = 0.15
    construction_threshold = 0.12
    book_sports_threshold = 0.05
    office_hours = (7 <= avg_hour <= 10 or 12 <= avg_hour <= 14)
    high_amount_threshold = 100  # –ú–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç–µ–Ω–≥–µ
    high_transaction_threshold = 5000
    salary_threshold = 0.003  # –î–æ–ª—è –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö —Ç—Ä–∞—Ç


    # –û—Ç–ª–∞–¥–∫–∞
    print(f"\nüîç –ö–ª–∞—Å—Ç–µ—Ä {cluster_id} ({len(cluster_data)} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    print(f"  total_amount: {total_amount:.1f}M‚Ç∏")
    print(f"  transaction_count: {transaction_count:.0f}")
    print(f"  unique_currencies: {unique_currencies:.1f}")
    print(f"  construction_spending_ratio: {ratios.get('construction', 0):.3f}")
    print(f"  style_spending_ratio: {ratios.get('cosmetic', 0) + ratios.get('fashion', 0) + ratios.get('beauty_salons', 0):.3f}")
    print(f"  auto_spending_ratio: {ratios.get('auto', 0):.3f}")
    print(f"  ecom_spending_ratio: {ratios.get('ecom', 0):.3f}")
    print(f"  pos_spending_ratio: {ratios.get('pos', 0):.3f}")
    print(f"  cash_withdrawal_spending_ratio: {ratios.get('cash_withdrawal', 0):.3f}")
    print(f"  salary_spending_ratio: {ratios.get('salary', 0):.3f}")


    # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    available_categories = [
        "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫", "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å", "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã", "–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å",
        "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏", "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫",
        "–£–¥–∞–ª—ë–Ω—â–∏–∫", "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–π –∫–∞—Ä—Ç—ã",
        "–°—Ä–µ–¥–Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"

    ]
    available_categories = [cat for cat in available_categories if cat not in used_labels]

    if not available_categories:
        return f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}"

    # 1. –ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫: –º–Ω–æ–≥–æ –≤–∞–ª—é—Ç, –≤—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    if unique_currencies >= min_currencies_travel and foreign_txn_ratio >= 0.5 and \
       total_amount >= high_amount_threshold and "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫" in available_categories:
        used_labels.append("–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫")
        return "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫"

    # 2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è cash_withdrawal, –º–∞–ª–æ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
    if ratios.get('cash_withdrawal', 0) >= fraud_threshold and \
       unique_merchants < max_merchants_fraud and \
       "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏" in available_categories:
        used_labels.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏")
        return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏"
    
    # –ù–æ–≤—ã–π —Ç–∏–ø: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–π –∫–∞—Ä—Ç—ã
    if ratios.get('pos', 0) >= 0.5 and ratios.get('ecom', 0) <= 0.2 and ratios.get('cash_withdrawal', 0) <= 0.2 and \
       "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–π –∫–∞—Ä—Ç—ã" in available_categories:
        used_labels.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–π –∫–∞—Ä—Ç—ã")
        return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–π –∫–∞—Ä—Ç—ã"


    if ratios.get('salary', 0) >= 0.3 and transaction_count <= 500 and total_amount < 10_000_000 and \
        "–°–∫—Ä–æ–º–Ω—ã–π –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç" in available_categories:
        used_labels.append("–°–∫—Ä–æ–º–Ω—ã–π –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç")
        return "–°–∫—Ä–æ–º–Ω—ã–π –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç"

    # 3. –£–¥–∞–ª—ë–Ω—â–∏–∫: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è ecom, –º–Ω–æ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    if ratios.get('ecom', 0) >= ecom_threshold and transaction_count >= high_transaction_threshold and \
       "–£–¥–∞–ª—ë–Ω—â–∏–∫" in available_categories:
        used_labels.append("–£–¥–∞–ª—ë–Ω—â–∏–∫")
        return "–£–¥–∞–ª—ë–Ω—â–∏–∫"

    if ratios.get('ecom', 0) >= 0.5 and transaction_count >= 1000 and \
        "–û–Ω–ª–∞–π–Ω –ø–æ–∫—É–ø–∞—Ç–µ–ª—å" in available_categories:
        used_labels.append("–û–Ω–ª–∞–π–Ω –ø–æ–∫—É–ø–∞—Ç–µ–ª—å")
        return "–û–Ω–ª–∞–π–Ω –ø–æ–∫—É–ø–∞—Ç–µ–ª—å"


    # 4. –ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è pos, –≤—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º
    if ratios.get('pos', 0) >= 0.3 and total_amount >= high_amount_threshold and \
       "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö" in available_categories:
        used_labels.append("–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö")
        return "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö"

    # 5. –ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è auto
    if ratios.get('auto', 0) >= auto_threshold and transaction_count >= min_transactions and \
       "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å" in available_categories:
        used_labels.append("–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å")
        return "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å"

    # 6. –ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è construction, –º–Ω–æ–≥–æ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
    if ratios.get('construction', 0) >= construction_threshold and \
       unique_merchants >= 50 and total_amount >= high_amount_threshold and \
       "–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å" in available_categories:
        used_labels.append("–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å")
        return "–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å"

    # 7. –õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è —Å—Ç–∏–ª—è
    style_spending_ratio = (ratios.get('cosmetic', 0) + ratios.get('fashion', 0) + 
                           ratios.get('beauty_salons', 0))
    if style_spending_ratio >= style_threshold and transaction_count >= min_transactions and \
       "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã" in available_categories:
        used_labels.append("–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã")
        return "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã"

    # 8. –û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫: —É–º–µ—Ä–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏, –æ—Ñ–∏—Å–Ω—ã–µ —á–∞—Å—ã
    if transaction_count <= 5000 and unique_merchants >= 50 and weekend_ratio >= 0.2 and \
       office_hours and ratios.get('salary', 0) > 0 and ratios.get('tax_payment', 0) > 0 and \
       "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫" in available_categories:
        used_labels.append("–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫")
        return "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫"

    # 9. –õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞: –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è book_and_sports
    if ratios.get('book_and_sports', 0) >= book_sports_threshold and \
       transaction_count >= min_transactions and \
       "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞" in available_categories:
        used_labels.append("–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞")
        return "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞"

    return "–û–±—ã—á–Ω—ã–π –∫–ª–∏–µ–Ω—Ç"

# –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_priorities = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    unique_currencies = cluster_data['unique_currencies'].mean()
    total_amount = cluster_data['total_amount'].mean() / 1_000_000
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean() for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean() for ttype in transaction_types.keys()})
    style_spending_ratio = (ratios.get('cosmetic', 0) + ratios.get('fashion', 0) + ratios.get('beauty_salons', 0))
    active_ratios = {
        'auto': ratios.get('auto', 0),
        'style': style_spending_ratio,
        'construction': ratios.get('construction', 0),
        'book_and_sports': ratios.get('book_and_sports', 0),
        'ecom': ratios.get('ecom', 0),
        'pos': ratios.get('pos', 0),
        'cash_withdrawal': ratios.get('cash_withdrawal', 0),
        'salary': ratios.get('salary', 0)

    }
    max_ratio = max(active_ratios.values(), default=0)
    priority = max(unique_currencies, total_amount, max_ratio)
    cluster_priorities.append((cluster_id, priority))

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
cluster_priorities.sort(key=lambda x: x[1], reverse=True)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
for cluster_id, priority in cluster_priorities:
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    size = len(cluster_data)
    print(f"\nüîπ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    cluster_label = interpret_cluster(cluster_data, used_labels, cluster_id)
    print(f"  ‚Ä¢ –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞: {cluster_label}")
    total_avg = cluster_data['total_amount'].mean()
    txn_avg = cluster_data['transaction_count'].mean()
    merchants_avg = cluster_data['unique_merchants'].mean()
    cities_avg = cluster_data['unique_cities'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    foreign_txn = cluster_data['has_foreign_txn'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean()
    print(f"  ‚Ä¢ –û–±—â–∞—è —Å—É–º–º–∞: {total_avg:,.0f} —Ç–µ–Ω–≥–µ")
    print(f"  ‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {txn_avg:.0f}")
    print(f"  ‚Ä¢ –ü—Ä–æ–¥–∞–≤—Ü–æ–≤: {merchants_avg:.1f}")
    print(f"  ‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤: {cities_avg:.1f}")
    print(f"  ‚Ä¢ –î–æ–ª—è –∑–∞–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {foreign_txn:.1%}")
    print(f"  ‚Ä¢ Weekend –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {weekend_ratio:.1%}")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç: {unique_currencies:.1f}")
    for cat in categories.keys():
        print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {cat}: {cluster_data[f'{cat}_spending_ratio'].mean():.1%}")
    for ttype in transaction_types.keys():
        print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {ttype}: {cluster_data[f'{ttype}_spending_ratio'].mean():.1%}")

# 8. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\nüé® –®–∞–≥ 8: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

# –ü—Ä–∏–º–µ–Ω—è–µ–º PCA —Å 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X_scaled)

# –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã
used_labels = []
cluster_labels = []
cluster_metrics = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    label = interpret_cluster(cluster_data, used_labels, cluster_id)
    avg_total_amount = cluster_data['total_amount'].mean() / 1_000_000
    avg_transaction_count = cluster_data['transaction_count'].mean()
    cluster_labels.append((cluster_id, label))
    cluster_metrics.append((cluster_id, avg_total_amount, avg_transaction_count))

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
total_amounts = client_features['total_amount'].values
transaction_counts = client_features['transaction_count'].values
amount_min, amount_max = total_amounts.min(), total_amounts.max()
if amount_max > amount_min:
    sizes = 10 + 90 * (total_amounts - amount_min) / (amount_max - amount_min)
else:
    sizes = np.full_like(total_amounts, 50.0)
count_min, count_max = transaction_counts.min(), transaction_counts.max()
if count_max > count_min:
    alphas = 0.3 + 0.5 * (transaction_counts - count_min) / (count_max - count_min)
else:
    alphas = np.full_like(transaction_counts, 0.5)

# 3D-–≥—Ä–∞—Ñ–∏–∫
fig = plt.figure(figsize=(14, 10))
ax = fig.add_subplot(111, projection='3d')
colors = plt.cm.tab20(np.linspace(0, 1, optimal_k))
for i in range(optimal_k):
    mask = final_labels == i
    cluster_label = next((label for cid, label in cluster_labels if cid == i), f"–ö–ª–∞—Å—Ç–µ—Ä {i}")
    avg_amount = next((amt for cid, amt, _ in cluster_metrics if cid == i), 0)
    avg_count = next((cnt for cid, _, cnt in cluster_metrics if cid == i), 0)
    legend_label = f"{cluster_label} (–°—É–º–º–∞: {avg_amount:.1f}M‚Ç∏, –¢—Ä–∞–Ω–∑: {avg_count:.0f})"
    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],
               c=[colors[i]], label=legend_label,
               s=sizes[mask], alpha=float(np.mean(alphas[mask])))

ax.set_title('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ 3D-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ PCA —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π')
ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
plt.tight_layout()
plt.savefig('pca_3d_clusters_with_metrics.png', bbox_inches='tight', dpi=300)
print("‚úÖ 3D-–≥—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'pca_3d_clusters_with_metrics.png'")

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤', fontsize=14)
cluster_sizes = [sum(final_labels == i) for i in range(optimal_k)]
axes[0, 0].bar(range(optimal_k), cluster_sizes, color=colors)
axes[0, 0].set_title('–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
axes[0, 0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤')
cluster_travel = client_features.groupby('cluster')['travel_spending_ratio'].mean()
axes[0, 1].bar(cluster_travel.index, cluster_travel.values, color=colors)
axes[0, 1].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è')
axes[0, 1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0, 1].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')
cluster_auto = client_features.groupby('cluster')['auto_spending_ratio'].mean()
axes[1, 0].bar(cluster_auto.index, cluster_auto.values, color=colors)
axes[1, 0].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å—ã')
axes[1, 0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1, 0].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')
axes[1, 1].axis('off')
plt.tight_layout()
plt.savefig('cluster_analysis.png', bbox_inches='tight', dpi=300)
print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'cluster_analysis.png'")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(K_range, inertias, 'bo-')
ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax1.set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
ax1.grid(True)
ax2.plot(K_range, silhouette_scores, 'ro-')
ax2.set_title('–°–∏–ª—É—ç—Ç –∞–Ω–∞–ª–∏–∑')
ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax2.set_ylabel('–°–∏–ª—É—ç—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7)
ax2.grid(True)
plt.tight_layout()
plt.savefig('elbow_silhouette.png', bbox_inches='tight', dpi=300)
print("‚úÖ –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è –∏ —Å–∏–ª—É—ç—Ç-–∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ 'elbow_silhouette.png'")
plt.show()

# 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüíæ –®–∞–≥ 9: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

output_columns = ['card_id', 'total_amount', 'transaction_count', 'unique_merchants',
                 'unique_cities', 'weekend_ratio', 'avg_hour', 'has_foreign_txn',
                 'unique_currencies', 'cluster'] + \
                [f'{cat}_spending_ratio' for cat in categories.keys()] + \
                [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]
final_results = client_features[output_columns].copy()
final_results['cluster_label'] = final_results['cluster'].apply(
    lambda x: interpret_cluster(client_features[client_features['cluster'] == x], [], x)
)
final_results.to_csv('client_segments.csv', index=False)
print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'client_segments.csv'")

used_labels_profiles = []
cluster_profiles = client_features.groupby('cluster')[key_profile_features].agg(['mean', 'median']).round(2)
clients_count = client_features.groupby('cluster').size()
cluster_profiles['clients_count'] = clients_count

cluster_profiles.to_csv('cluster_profiles_summary.csv')
print("‚úÖ –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'cluster_profiles_summary.csv'")