# –û–±–ª–µ–≥—á–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
# –ê–≤—Ç–æ—Ä: Erik (Decentra) - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import warnings
import os
import gc
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
pd.set_option('display.precision', 2)
plt.style.use('default')  # –ü—Ä–æ—Å—Ç–æ–π —Å—Ç–∏–ª—å

print("üöÄ –û–ë–õ–ï–ì–ß–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í–°–ö–ò–• –¢–†–ê–ù–ó–ê–ö–¶–ò–ô")
print("=" * 55)
print("üéØ –¶–µ–ª—å: –°—Ç–∞–±–∏–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
print("‚ö° –ü–æ–¥—Ö–æ–¥: –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ + –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã")

# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
print("\nüìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

data_path = "/kaggle/input/decentra"
parquet_files = []

if os.path.exists(data_path):
    for filename in os.listdir(data_path):
        if filename.endswith('.parquet'):
            parquet_files.append(os.path.join(data_path, filename))
            print(f"  üìÅ –ù–∞–π–¥–µ–Ω: {filename}")

df = None
if parquet_files:
    file_path = parquet_files[0]
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º: {file_path}")
    
    try:
        df = pd.read_parquet(file_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape[0]:,} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {df['card_id'].nunique():,}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏
        memory_usage = df.memory_usage(deep=True).sum() / 1024**3
        print(f"üíæ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {memory_usage:.1f} GB")
        
        if memory_usage > 8:
            print("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ - –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä–∫—É")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        df = None

if df is None:
    print("üö´ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –∞–Ω–∞–ª–∏–∑")
    exit()

# 2. –ë–´–°–¢–†–ê–Ø –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•
print("\nüßπ –®–∞–≥ 2: –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

original_size = len(df)
df = df[df['transaction_amount_kzt'] > 0]
df['transaction_timestamp'] = pd.to_datetime(df['transaction_timestamp'], errors='coerce')
df = df[df['transaction_timestamp'].notna()]

print(f"–û—á–∏—Å—Ç–∫–∞: {original_size:,} ‚Üí {len(df):,} –∑–∞–ø–∏—Å–µ–π")

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
df['hour'] = df['transaction_timestamp'].dt.hour
df['day_of_week'] = df['transaction_timestamp'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# 3. –£–ú–ù–ê–Ø –í–´–ë–û–†–ö–ê –ö–õ–ò–ï–ù–¢–û–í
print("\nüéØ –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏...")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
MAX_CLIENTS = 25000
unique_clients_total = df['card_id'].nunique()

print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {unique_clients_total:,}")

if unique_clients_total > MAX_CLIENTS:
    print(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–µ–º –≤—ã–±–æ—Ä–∫—É –∏–∑ {MAX_CLIENTS:,}")
    
    # –ë—ã—Å—Ç—Ä–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    client_activity = df.groupby('card_id').agg({
        'transaction_amount_kzt': ['count', 'sum'],
        'transaction_timestamp': ['min', 'max']
    })
    
    client_activity.columns = ['txn_count', 'total_amount', 'first_txn', 'last_txn']
    client_activity['activity_days'] = (client_activity['last_txn'] - client_activity['first_txn']).dt.days + 1
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    client_activity['activity_level'] = pd.cut(
        client_activity['txn_count'], 
        bins=[0, 10, 50, 200, float('inf')], 
        labels=['Low', 'Medium', 'High', 'VeryHigh']
    )
    
    # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
    sample_clients = []
    for level in ['Low', 'Medium', 'High', 'VeryHigh']:
        level_clients = client_activity[client_activity['activity_level'] == level].index
        sample_size = min(MAX_CLIENTS // 4, len(level_clients))
        if sample_size > 0:
            sample = np.random.choice(level_clients, sample_size, replace=False)
            sample_clients.extend(sample)
    
    # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–æ MAX_CLIENTS —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–∞–º–∏
    remaining = MAX_CLIENTS - len(sample_clients)
    if remaining > 0:
        all_other = client_activity.index.difference(sample_clients)
        if len(all_other) > 0:
            additional = np.random.choice(all_other, min(remaining, len(all_other)), replace=False)
            sample_clients.extend(additional)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    df = df[df['card_id'].isin(sample_clients)]
    print(f"‚úÖ –í—ã–±–æ—Ä–∫–∞: {len(sample_clients):,} –∫–ª–∏–µ–Ω—Ç–æ–≤, {len(df):,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
    del client_activity
    gc.collect()

# 4. –°–û–ó–î–ê–ù–ò–ï –ö–õ–Æ–ß–ï–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
print("\nüîß –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤...")

# –¢–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
print("  üìä –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏...")
basic_features = df.groupby('card_id').agg({
    'transaction_amount_kzt': ['sum', 'mean', 'std', 'count', 'median'],
    'transaction_timestamp': ['min', 'max'],
    'merchant_id': 'nunique',
    'merchant_city': 'nunique'
}).reset_index()

basic_features.columns = ['card_id', 'total_amount', 'avg_amount', 'std_amount', 
                         'transaction_count', 'median_amount', 'first_transaction', 
                         'last_transaction', 'unique_merchants', 'unique_cities']

print("  ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...")
time_features = df.groupby('card_id').agg({
    'hour': 'mean',
    'is_weekend': 'mean',
    'day_of_week': lambda x: x.mode().iloc[0] if len(x) > 0 else 0
}).reset_index()

time_features.columns = ['card_id', 'avg_hour', 'weekend_ratio', 'preferred_day']

print("  üè™ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—ã...")
category_features = df.groupby('card_id').agg({
    'mcc_category': 'nunique',
    'transaction_type': 'nunique'
}).reset_index()

category_features.columns = ['card_id', 'unique_categories', 'unique_txn_types']

# –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
client_features = basic_features.merge(time_features, on='card_id', how='left')
client_features = client_features.merge(category_features, on='card_id', how='left')

# –í—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
client_features['activity_days'] = (client_features['last_transaction'] - 
                                   client_features['first_transaction']).dt.days + 1
client_features['avg_daily_transactions'] = client_features['transaction_count'] / client_features['activity_days']
client_features['coefficient_variation'] = client_features['std_amount'] / client_features['avg_amount']
client_features['avg_monthly_amount'] = client_features['total_amount'] / (client_features['activity_days'] / 30)

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ float
print("üîß –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
client_features = client_features.fillna(0)
client_features['coefficient_variation'] = client_features['coefficient_variation'].replace([np.inf, -np.inf], 0)

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤—Å–µ—Ö —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∫ float
numeric_cols = client_features.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    if col != 'card_id':
        client_features[col] = pd.to_numeric(client_features[col], errors='coerce').fillna(0).astype(float)

print("‚úÖ –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ float64")

# –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
del df
gc.collect()

print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(client_features.columns)-1} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(client_features):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")

# 5. –ü–û–î–ì–û–¢–û–í–ö–ê –ö –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò
print("\n‚öôÔ∏è –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
key_features = [
    'total_amount', 'avg_amount', 'transaction_count', 'activity_days',
    'unique_merchants', 'unique_cities', 'weekend_ratio', 'avg_hour',
    'unique_categories', 'coefficient_variation', 'avg_daily_transactions'
]

print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(key_features)} –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
X = client_features[key_features].copy()

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ float –ü–ï–†–ï–î –ª—é–±—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
print("üîß –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∫ float...")
for col in X.columns:
    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)

# –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ (—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤...")
for col in X.columns:
    Q99 = float(X[col].quantile(0.99))
    Q01 = float(X[col].quantile(0.01))
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –≤—ã–±—Ä–æ—Å–æ–≤
    X.loc[X[col] > Q99, col] = Q99
    X.loc[X[col] < Q01, col] = Q01

# –ó–∞–º–µ–Ω—è–µ–º inf –∏ nan
X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤
print("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤...")
for col in X.columns:
    if X[col].dtype != 'float64':
        print(f"  –ò—Å–ø—Ä–∞–≤–ª—è–µ–º {col}: {X[col].dtype} ‚Üí float64")
        X[col] = X[col].astype(float)

print(f"–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape}")
print(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {X.dtypes.unique()}")

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

# 6. –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø
print("\nüéØ –®–∞–≥ 6: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ K-Means –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)...")

n_clients = len(X_scaled)
print(f"–ö–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {n_clients:,}")

# –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
print("üìä –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

K_range = range(3, 9)
inertias = []
silhouette_scores = []

for k in K_range:
    print(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º K={k}...", end="")
    
    # –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=5, max_iter=100)
    labels = kmeans.fit_predict(X_scaled)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    inertias.append(kmeans.inertia_)
    
    # –°–∏–ª—É—ç—Ç –Ω–∞ –≤—ã–±–æ—Ä–∫–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    if n_clients > 5000:
        sample_size = 3000
        sample_indices = np.random.choice(n_clients, sample_size, replace=False)
        sil_score = silhouette_score(X_scaled[sample_indices], labels[sample_indices])
    else:
        sil_score = silhouette_score(X_scaled, labels)
    
    silhouette_scores.append(sil_score)
    print(f" —Å–∏–ª—É—ç—Ç: {sil_score:.3f}")

# –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ K
optimal_k = K_range[np.argmax(silhouette_scores)]
best_silhouette = max(silhouette_scores)

print(f"\n‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ K: {optimal_k} (—Å–∏–ª—É—ç—Ç: {best_silhouette:.3f})")

# –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å –º–∞–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
if optimal_k < 5:
    optimal_k = 6
    print(f"üîß –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

# –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å K={optimal_k}...")
final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
final_labels = final_kmeans.fit_predict(X_scaled)

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
client_features['cluster'] = final_labels

print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

# 7. –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüìà –®–∞–≥ 7: –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
cluster_distribution = pd.Series(final_labels).value_counts().sort_index()
for cluster_id, count in cluster_distribution.items():
    percentage = count / len(client_features) * 100
    print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count:,} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")

# –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
print(f"\nüí° –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")

key_profile_features = ['total_amount', 'avg_amount', 'transaction_count', 
                       'unique_merchants', 'weekend_ratio', 'avg_hour']

for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    size = len(cluster_data)
    
    print(f"\nüîπ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    
    # –¢–æ–ø-3 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    total_avg = cluster_data['total_amount'].mean()
    txn_avg = cluster_data['transaction_count'].mean()
    merchants_avg = cluster_data['unique_merchants'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    
    print(f"  ‚Ä¢ –û–±—â–∞—è —Å—É–º–º–∞: {total_avg:,.0f} —Ç–µ–Ω–≥–µ")
    print(f"  ‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {txn_avg:.0f}")
    print(f"  ‚Ä¢ –ü—Ä–æ–¥–∞–≤—Ü–æ–≤: {merchants_avg:.1f}")
    print(f"  ‚Ä¢ Weekend –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {weekend_ratio:.1%}")

# 8. –ü–†–û–°–¢–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\nüé® –®–∞–≥ 8: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

# PCA –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# –ü—Ä–æ—Å—Ç—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤', fontsize=14)

# 1. PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))
for i in range(optimal_k):
    mask = final_labels == i
    axes[0,0].scatter(X_pca[mask, 0], X_pca[mask, 1], 
                     c=[colors[i]], label=f'–ö–ª–∞—Å—Ç–µ—Ä {i}', alpha=0.6, s=20)

axes[0,0].set_title('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
axes[0,0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
axes[0,0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
axes[0,0].legend()

# 2. –†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_sizes = [sum(final_labels == i) for i in range(optimal_k)]
axes[0,1].bar(range(optimal_k), cluster_sizes, color=colors)
axes[0,1].set_title('–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
axes[0,1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0,1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤')

# 3. –û–±—â–∏–µ —Å—É–º–º—ã –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
cluster_means = client_features.groupby('cluster')['total_amount'].mean()
axes[1,0].bar(cluster_means.index, cluster_means.values, color=colors)
axes[1,0].set_title('–°—Ä–µ–¥–Ω–∏–µ –æ–±—â–∏–µ —Å—É–º–º—ã')
axes[1,0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1,0].set_ylabel('–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ (—Ç–µ–Ω–≥–µ)')
axes[1,0].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))

# 4. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
cluster_activity = client_features.groupby('cluster')['transaction_count'].mean()
axes[1,1].bar(cluster_activity.index, cluster_activity.values, color=colors)
axes[1,1].set_title('–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å')
axes[1,1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1,1].set_ylabel('–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π')

plt.tight_layout()
plt.show()

# –ì—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ K
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

ax1.plot(K_range, inertias, 'bo-')
ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax1.set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
ax1.grid(True)

ax2.plot(K_range, silhouette_scores, 'ro-')
ax2.set_title('–°–∏–ª—É—ç—Ç –∞–Ω–∞–ª–∏–∑')
ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')  
ax2.set_ylabel('–°–∏–ª—É—ç—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7)
ax2.grid(True)

plt.tight_layout()
plt.show()

# 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüíæ –®–∞–≥ 9: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

# –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
output_columns = ['card_id', 'total_amount', 'avg_amount', 'transaction_count', 
                 'activity_days', 'unique_merchants', 'unique_cities', 
                 'weekend_ratio', 'avg_hour', 'unique_categories', 'cluster']

final_results = client_features[output_columns].copy()
final_results.to_csv('lightweight_client_segments.csv', index=False)
print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'lightweight_client_segments.csv'")

# –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_profiles = client_features.groupby('cluster')[key_features].agg(['mean', 'median']).round(2)
cluster_profiles.to_csv('cluster_profiles_summary.csv')
print("‚úÖ –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'cluster_profiles_summary.csv'")

# –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
summary = {
    'total_clients_analyzed': len(client_features),
    'clusters_found': optimal_k,
    'silhouette_score': best_silhouette,
    'features_used': len(key_features),
    'largest_cluster_size': max(cluster_sizes),
    'smallest_cluster_size': min(cluster_sizes)
}

summary_df = pd.DataFrame([summary])
summary_df.to_csv('analysis_summary.csv', index=False)
print("‚úÖ –°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'analysis_summary.csv'")

print(f"\nüéâ –û–ë–õ–ï–ì–ß–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
print("=" * 55)
print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
print(f"‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∫–ª–∏–µ–Ω—Ç–æ–≤: {len(client_features):,}")
print(f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(key_features)}")
print(f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_k}")
print(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {best_silhouette:.3f}")
print(f"‚Ä¢ –°–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–ª–∞—Å—Ç–µ—Ä: {max(cluster_sizes):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")
print(f"‚Ä¢ –°–∞–º—ã–π –º–∞–ª–µ–Ω—å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä: {min(cluster_sizes):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")

balance_ratio = min(cluster_sizes) / max(cluster_sizes)
if balance_ratio > 0.1:
    print("‚úÖ –ö–ª–∞—Å—Ç–µ—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã")
elif balance_ratio > 0.05:
    print("‚ö†Ô∏è –ï—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
else:
    print("‚ùå –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å - –æ–¥–∏–Ω –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –∫–ª–∞—Å—Ç–µ—Ä")

print(f"\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
print("‚Ä¢ lightweight_client_segments.csv - –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
print("‚Ä¢ cluster_profiles_summary.csv - –ø—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
print("‚Ä¢ analysis_summary.csv - —Å–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
print("\n‚ö° –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã!")
print("üéØ –ì–æ—Ç–æ–≤–æ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∏ –±–∏–∑–Ω–µ—Å-—Ä–µ—à–µ–Ω–∏–π!")