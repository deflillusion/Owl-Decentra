import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import warnings
import os
import gc
warnings.filterwarnings('ignore')

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
categories = {
    'auto': [5541, 5542, 7513, 7531, 5599],
    'cosmetic': [5999, 7298, 5945, 5977],
    'fashion': [5651, 5699, 5691],
    'beauty_salons': [7230],
    'construction': [5311, 5310, 5122, 5712, 5200, 5211, 5722, 5732, 5734],
    'book_and_sports': [5941, 5942],
    'tax_payment': [9311],           # –ù–∞–ª–æ–≥–æ–≤—ã–µ –ø–ª–∞—Ç–µ–∂–∏
    'travel': [3000, 3010, 3050, 3500, 7011]  # –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è (–∞–≤–∏–∞–±–∏–ª–µ—Ç—ã, –æ—Ç–µ–ª–∏ –∏ —Ç.–¥.)
}

# –¢–∏–ø—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è, –µ—Å–ª–∏ transaction_type –¥–æ—Å—Ç—É–ø–µ–Ω)
transaction_types = {
    'incoming_transfer': ['P2P_IN'],
    'outgoing_transfer': ['P2P_OUT'],
    'ecom': ['ECOM'],
    'pos': ['POS'],
    'cash_withdrawal': ['ATM_WITHDRAWAL'],  # –ë–∞–Ω–∫–æ–º–∞—Ç—ã
    'salary': ['SALARY'],                 # –ó–∞—Ä–ø–ª–∞—Ç–∞ (MCC —É—Å–ª–æ–≤–Ω—ã–π)
}

# –ü–æ—Ä–æ–≥ –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
min_currencies_travel = 3

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
pd.set_option('display.precision', 2)
plt.style.use('default')

print("üöÄ –û–ë–õ–ï–ì–ß–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í–°–ö–ò–• –¢–†–ê–ù–ó–ê–ö–¶–ò–ô")
print("=" * 55)
print("üéØ –¶–µ–ª—å: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏, –ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª–∏ –∏ —Ç.–¥.)")
print("‚ö° –ü–æ–¥—Ö–æ–¥: –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ + –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")

# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
print("\nüìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

data_path = r"C:\Users\ksyus\Desktop\Education\Owl-Decentra\hackaton\data"
parquet_files = []

if os.path.exists(data_path):
    for filename in os.listdir(data_path):
        if filename.endswith('.parquet'):
            parquet_files.append(os.path.join(data_path, filename))
            print(f"  üìÅ –ù–∞–π–¥–µ–Ω: {filename}")
else:
    print(f"‚ùå –ü–∞–ø–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_path}")
    exit()

df = None
if parquet_files:
    file_path = parquet_files[0]
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º: {file_path}")
    try:
        df = pd.read_parquet(file_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape[0]:,} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {df['card_id'].nunique():,}")
        memory_usage = df.memory_usage(deep=True).sum() / 1024**3
        print(f"üíæ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {memory_usage:.1f} GB")
        if memory_usage > 8:
            print("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ - –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä–∫—É")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        df = None
else:
    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ parquet-—Ñ–∞–π–ª–∞")
    exit()

if df is None:
    print("üö´ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –∞–Ω–∞–ª–∏–∑")
    exit()

# 2. –ë–´–°–¢–†–ê–Ø –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•
print("\nüßπ –®–∞–≥ 2: –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

original_size = len(df)
df = df[df['transaction_amount_kzt'] > 0]
df['transaction_timestamp'] = pd.to_datetime(df['transaction_timestamp'], errors='coerce')
df = df[df['transaction_timestamp'].notna()]
print(f"–û—á–∏—Å—Ç–∫–∞: {original_size:,} ‚Üí {len(df):,} –∑–∞–ø–∏—Å–µ–π")

df['hour'] = df['transaction_timestamp'].dt.hour
df['day_of_week'] = df['transaction_timestamp'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# 3. –£–ú–ù–ê–Ø –í–´–ë–û–†–ö–ê –ö–õ–ò–ï–ù–¢–û–í
print("\nüéØ –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏...")

MAX_CLIENTS = 25000
unique_clients_total = df['card_id'].nunique()
print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {unique_clients_total:,}")

if unique_clients_total > MAX_CLIENTS:
    print(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–µ–º –≤—ã–±–æ—Ä–∫—É –∏–∑ {MAX_CLIENTS:,}")
    client_activity = df.groupby('card_id').agg({
        'transaction_amount_kzt': ['count', 'sum'],
        'transaction_timestamp': ['min', 'max']
    })
    client_activity.columns = ['txn_count', 'total_amount', 'first_txn', 'last_txn']
    client_activity['activity_days'] = (client_activity['last_txn'] - client_activity['first_txn']).dt.days + 1
    client_activity['activity_level'] = pd.cut(
        client_activity['txn_count'],
        bins=[0, 10, 50, 200, float('inf')],
        labels=['Low', 'Medium', 'High', 'VeryHigh']
    )
    sample_clients = []
    for level in ['Low', 'Medium', 'High', 'VeryHigh']:
        level_clients = client_activity[client_activity['activity_level'] == level].index
        sample_size = min(MAX_CLIENTS // 4, len(level_clients))
        if sample_size > 0:
            sample = np.random.choice(level_clients, sample_size, replace=False)
            sample_clients.extend(sample)
    remaining = MAX_CLIENTS - len(sample_clients)
    if remaining > 0:
        all_other = client_activity.index.difference(sample_clients)
        if len(all_other) > 0:
            additional = np.random.choice(all_other, min(remaining, len(all_other)), replace=False)
            sample_clients.extend(additional)
    df = df[df['card_id'].isin(sample_clients)]
    print(f"‚úÖ –í—ã–±–æ—Ä–∫–∞: {len(sample_clients):,} –∫–ª–∏–µ–Ω—Ç–æ–≤, {len(df):,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    del client_activity
    gc.collect()

# 4. –°–û–ó–î–ê–ù–ò–ï –ö–õ–Æ–ß–ï–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
print("\nüîß –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤...")

# –û—Ç–ª–∞–¥–∫–∞: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("üìã –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö:", df.columns.tolist())
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ MCC-–∫–æ–¥—ã:", df['merchant_mcc'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:", df['transaction_type'].value_counts(dropna=False).head(10))
print("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–ª—é—Ç—ã:", df['transaction_currency'].value_counts(dropna=False).head(10))
print("üìã –ö–ª–∏–µ–Ω—Ç—ã —Å >3 –≤–∞–ª—é—Ç–∞–º–∏:", len(df[df['transaction_currency'].isin(['TRY', 'CNY', 'AED', 'AMD', 'BYN', 'KGS', 'UZS', 'USD', 'GEL', 'EUR'])].groupby('card_id').filter(lambda x: x['transaction_currency'].nunique() > 3)))

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è merchant_mcc –≤ —Å—Ç—Ä–æ–∫–∏
df['merchant_mcc'] = df['merchant_mcc'].astype(str)

# –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
print("  üìä –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏...")
basic_features = df.groupby('card_id').agg({
    'transaction_amount_kzt': ['sum', 'mean', 'std', 'count', 'median'],
    'transaction_timestamp': ['min', 'max'],
    'merchant_id': 'nunique',
    'merchant_city': 'nunique',
    'acquirer_country_iso': lambda x: (x != 'KAZ').any()
}).reset_index()
basic_features.columns = ['card_id', 'total_amount', 'avg_amount', 'std_amount',
                         'transaction_count', 'median_amount', 'first_transaction',
                         'last_transaction', 'unique_merchants', 'unique_cities', 'has_foreign_txn']

# –ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç
valid_currencies = ['TRY', 'CNY', 'AED', 'AMD', 'BYN', 'KGS', 'UZS', 'USD', 'GEL', 'EUR']
currency_features = df[df['transaction_currency'].isin(valid_currencies)].groupby('card_id').agg({
    'transaction_currency': 'nunique'
}).reset_index()
currency_features.columns = ['card_id', 'unique_currencies']
basic_features = basic_features.merge(currency_features, on='card_id', how='left')
basic_features['unique_currencies'] = basic_features['unique_currencies'].fillna(0).astype(float)

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
print("  ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...")
time_features = df.groupby('card_id').agg({
    'hour': 'mean',
    'is_weekend': 'mean',
    'day_of_week': lambda x: x.mode().iloc[0] if len(x) > 0 else 0
}).reset_index()
time_features.columns = ['card_id', 'avg_hour', 'weekend_ratio', 'preferred_day']

# –†–∞—Å—á–µ—Ç —Ç—Ä–∞—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
print("  üè™ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—ã...")
client_features = basic_features.merge(time_features, on='card_id', how='left')

for category, mcc_list in categories.items():
    filtered_df = df[df['merchant_mcc'].isin([str(m) for m in mcc_list])]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {category}: {len(filtered_df)}")
    category_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    category_spending.columns = ['card_id', f'{category}_spending_amount', f'{category}_transaction_count']
    client_features = client_features.merge(category_spending, on='card_id', how='left')

for ttype, type_list in transaction_types.items():
    filtered_df = df[df['transaction_type'].isin(type_list)]
    print(f"üìà –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è {ttype}: {len(filtered_df)}")
    type_spending = filtered_df.groupby('card_id').agg({
        'transaction_amount_kzt': 'sum',
        'transaction_id': 'count'
    }).reset_index()
    type_spending.columns = ['card_id', f'{ttype}_spending_amount', f'{ttype}_transaction_count']
    client_features = client_features.merge(type_spending, on='card_id', how='left')

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
category_columns = []
for category in categories.keys():
    category_columns.extend([f'{category}_spending_amount', f'{category}_transaction_count'])
for ttype in transaction_types.keys():
    category_columns.extend([f'{ttype}_spending_amount', f'{ttype}_transaction_count'])
client_features[category_columns] = client_features[category_columns].fillna(0)

# –†–∞—Å—á–µ—Ç –¥–æ–ª–µ–π
ratio_columns = []
for category in categories.keys():
    client_features[f'{category}_spending_ratio'] = client_features[f'{category}_spending_amount'] / client_features['total_amount']
    client_features[f'{category}_transaction_ratio'] = client_features[f'{category}_transaction_count'] / client_features['transaction_count']
    ratio_columns.extend([f'{category}_spending_ratio', f'{category}_transaction_ratio'])
for ttype in transaction_types.keys():
    client_features[f'{ttype}_spending_ratio'] = client_features[f'{ttype}_spending_amount'] / client_features['total_amount']
    client_features[f'{ttype}_transaction_ratio'] = client_features[f'{ttype}_transaction_count'] / client_features['transaction_count']
    ratio_columns.extend([f'{ttype}_spending_ratio', f'{ttype}_transaction_ratio'])

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
client_features[ratio_columns] = client_features[ratio_columns].replace([np.inf, -np.inf], 0).fillna(0)

# –î—Ä—É–≥–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
client_features['activity_days'] = (client_features['last_transaction'] - client_features['first_transaction']).dt.days + 1
client_features['avg_daily_transactions'] = client_features['transaction_count'] / client_features['activity_days']
client_features['coefficient_variation'] = client_features['std_amount'] / client_features['avg_amount']
client_features['avg_monthly_amount'] = client_features['total_amount'] / (client_features['activity_days'] / 30)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
client_features = client_features.fillna(0)
client_features['coefficient_variation'] = client_features['coefficient_variation'].replace([np.inf, -np.inf], 0)
numeric_cols = client_features.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    if col != 'card_id':
        client_features[col] = pd.to_numeric(client_features[col], errors='coerce').fillna(0).astype(float)

print("‚úÖ –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ float64")
del df
gc.collect()
print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(client_features.columns)-1} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(client_features):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")

# 5. –ü–û–î–ì–û–¢–û–í–ö–ê –ö –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò
print("\n‚öôÔ∏è –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")

# –¢–Æ–ù–ò–ù–ì: –î–æ–±–∞–≤–ª—è–µ–º unique_currencies –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
key_features = [f'{cat}_spending_ratio' for cat in categories.keys()] + \
               [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()] + \
               ['has_foreign_txn', 'unique_currencies']
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(key_features)} –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {key_features}")

# –¢–Æ–ù–ò–ù–ì: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
feature_weights = {
    'auto_spending_ratio': 3.0,    # –î–ª—è "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª–µ–π"
    'cosmetic_spending_ratio': 2.0,
    'fashion_spending_ratio': 2.0,
    'beauty_salons_spending_ratio': 2.0, # –î–ª—è "–õ—é–±–∏—Ç–µ–ª—è —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã"
    'construction_spending_ratio': 2.5, # –î–ª—è "–°—Ç—Ä–æ–∏—Ç–µ–ª—è"
    'book_and_sports_spending_ratio': 2.0, # –î–ª—è "–õ—é–±–∏—Ç–µ–ª—è –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞"
    'cash_withdrawal_spending_ratio': 2.5, # –î–ª—è "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞–ª–∏—á–Ω—ã–º–∏"
    'incoming_transfer_spending_ratio': 2.0,
    'outgoing_transfer_spending_ratio': 2.0,
    'ecom_spending_ratio': 2.5,    # –î–ª—è "–£–¥–∞–ª—ë–Ω—â–∏–∫–∞"
    'pos_spending_ratio': 2.0,     # –î–ª—è "–ü–æ–∫—É–ø–∞—Ç–µ–ª—è –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö"
    'salary_spending_ratio': 1.5,  # –î–ª—è "–û—Ñ–∏—Å–Ω–æ–≥–æ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞"
    'tax_payment_spending_ratio': 1.5,
    'has_foreign_txn': 1.5,
    'unique_currencies': 2.5,      # –î–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
}

X = client_features[key_features].copy()
for feature, weight in feature_weights.items():
    if feature in X.columns:
        X[feature] = X[feature] * weight

for col in X.columns:
    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)

print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤...")
for col in X.columns:
    Q99 = float(X[col].quantile(0.99))
    Q01 = float(X[col].quantile(0.01))
    X.loc[X[col] > Q99, col] = Q99
    X.loc[X[col] < Q01, col] = Q01

X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

print("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤...")
for col in X.columns:
    if X[col].dtype != 'float64':
        print(f"  –ò—Å–ø—Ä–∞–≤–ª—è–µ–º {col}: {X[col].dtype} ‚Üí float64")
        X[col] = X[col].astype(float)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

# 6. –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø
print("\nüéØ –®–∞–≥ 6: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è...")

n_clients = len(X_scaled)
print(f"–ö–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {n_clients:,}")

# –¢–Æ–ù–ò–ù–ì: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —á–∏—Å–ª–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π (9)
K_range = range(5, 10)
inertias = []
silhouette_scores = []

for k in K_range:
    print(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º K={k}...", end="")
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=5, max_iter=100)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    if n_clients > 5000:
        sample_size = 3000
        sample_indices = np.random.choice(n_clients, sample_size, replace=False)
        sil_score = silhouette_score(X_scaled[sample_indices], labels[sample_indices])
    else:
        sil_score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(sil_score)
    print(f" —Å–∏–ª—É—ç—Ç: {sil_score:.3f}")

optimal_k = K_range[np.argmax(silhouette_scores)]
best_silhouette = max(silhouette_scores)
print(f"\n‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ K: {optimal_k} (—Å–∏–ª—É—ç—Ç: {best_silhouette:.3f})")

if optimal_k > 9:
    optimal_k = 9  # –¢–Æ–ù–ò–ù–ì: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    print(f"üîß –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å K={optimal_k}...")
final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
final_labels = final_kmeans.fit_predict(X_scaled)
client_features['cluster'] = final_labels
print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

# 7. –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüìà –®–∞–≥ 7: –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
cluster_distribution = pd.Series(final_labels).value_counts().sort_index()
for cluster_id, count in cluster_distribution.items():
    percentage = count / len(client_features) * 100
    print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count:,} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")

print(f"\nüí° –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
key_profile_features = ['total_amount', 'transaction_count', 'unique_merchants', 'unique_cities',
                       'weekend_ratio', 'avg_hour', 'has_foreign_txn', 'unique_currencies'] + \
                      [f'{cat}_spending_ratio' for cat in categories.keys()] + \
                      [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]

def interpret_cluster(cluster_data, used_labels, cluster_id):
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean() for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean() for ttype in transaction_types.keys()})
    transaction_count = cluster_data['transaction_count'].mean()
    unique_merchants = cluster_data['unique_merchants'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    avg_hour = cluster_data['avg_hour'].mean()

    # –¢–Æ–ù–ò–ù–ì: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    category_threshold = 0.2  # –ü–æ—Ä–æ–≥ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –¥–æ–ª–µ —Ç—Ä–∞—Ç
    fraud_threshold = 0.5    # –ü–æ—Ä–æ–≥ –¥–ª—è "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞–ª–∏—á–Ω—ã–º–∏"
    min_transactions = 50    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    max_merchants_fraud = 200 # –ú–∞–∫—Å–∏–º—É–º –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –¥–ª—è "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞–ª–∏—á–Ω—ã–º–∏"
    ecom_threshold = 0.3     # –ü–æ—Ä–æ–≥ –¥–ª—è "–£–¥–∞–ª—ë–Ω—â–∏–∫–∞"
    office_hours = (7 <= avg_hour <= 10 or 12 <= avg_hour <= 14)
    valid_currencies = ['TRY', 'CNY', 'AED', 'AMD', 'BYN', 'KGS', 'UZS', 'USD', 'GEL', 'EUR']
    min_currencies_travel = 3 # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"

    # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ)
    available_categories = [
        "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫", "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å", "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã", "–°—Ç—Ä–æ–∏—Ç–µ–ª—å",
        "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏", "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫",
        "–£–¥–∞–ª—ë–Ω—â–∏–∫", "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö"
    ]
    available_categories = [cat for cat in available_categories if cat not in used_labels]

    # –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º "–ö–ª–∞—Å—Ç–µ—Ä N"
    if not available_categories:
        return f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞"
    unique_currencies = cluster_data['unique_currencies'].mean() if 'unique_currencies' in cluster_data else 0
    if unique_currencies > min_currencies_travel and "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫" in available_categories:
        used_labels.append("–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫")
        return "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫"

    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ–ª—è –¥–ª—è "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã"
    style_spending_ratio = (ratios.get('cosmetic', 0) + 
                           ratios.get('fashion', 0) + 
                           ratios.get('beauty_salons', 0))

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    active_categories = {
        'auto': ratios.get('auto', 0),
        'style': style_spending_ratio,
        'construction': ratios.get('construction', 0),
        'book_and_sports': ratios.get('book_and_sports', 0),
        'ecom': ratios.get('ecom', 0),
        'pos': ratios.get('pos', 0)
    }
    max_category = max(active_categories, key=active_categories.get, default='none')
    max_ratio = active_categories.get(max_category, 0)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–æ–ª–µ —Ç—Ä–∞—Ç
    if max_ratio > category_threshold and transaction_count >= min_transactions:
        if max_category == 'auto' and "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å" in available_categories:
            used_labels.append("–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å")
            return "–ê–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å"
        elif max_category == 'style' and "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã" in available_categories:
            used_labels.append("–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã")
            return "–õ—é–±–∏—Ç–µ–ª—å —É—Ö–æ–¥–∞ –∏ –º–æ–¥—ã"
        elif max_category == 'construction' and "–°—Ç—Ä–æ–∏—Ç–µ–ª—å" in available_categories:
            used_labels.append("–°—Ç—Ä–æ–∏—Ç–µ–ª—å")
            return "–°—Ç—Ä–æ–∏—Ç–µ–ª—å"
        elif max_category == 'book_and_sports' and "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞" in available_categories:
            used_labels.append("–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞")
            return "–õ—é–±–∏—Ç–µ–ª—å –∫–Ω–∏–≥ –∏ —Å–ø–æ—Ä—Ç–∞"
        elif max_category == 'ecom' and max_ratio >= ecom_threshold and "–£–¥–∞–ª—ë–Ω—â–∏–∫" in available_categories:
            used_labels.append("–£–¥–∞–ª—ë–Ω—â–∏–∫")
            return "–£–¥–∞–ª—ë–Ω—â–∏–∫"
        elif max_category == 'pos' and "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö" in available_categories:
            used_labels.append("–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö")
            return "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞–ª–∏—á–Ω—ã–º–∏"
    if (ratios.get('cash_withdrawal', 0) > fraud_threshold or
        ratios.get('incoming_transfer', 0) > fraud_threshold or
        ratios.get('outgoing_transfer', 0) > fraud_threshold) and \
        unique_merchants < max_merchants_fraud and \
        "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏" in available_categories:
        used_labels.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏")
        return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ª–∏—á–Ω—ã–º–∏"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "–û—Ñ–∏—Å–Ω–æ–≥–æ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞"
    if (transaction_count <= 5000 and 
        unique_merchants >= 100 and 
        weekend_ratio > 0.5 and 
        office_hours and 
        ratios.get('salary', 0) > 0 and 
        ratios.get('tax_payment', 0) > 0 and 
        "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫" in available_categories):
        used_labels.append("–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫")
        return "–û—Ñ–∏—Å–Ω—ã–π —Ä–∞–±–æ—Ç–Ω–∏–∫"

    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏
    return "–û–±—ã—á–Ω—ã–π –∫–ª–∏–µ–Ω—Ç"

# –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
cluster_priorities = []
for cluster_id in sorted(client_features['cluster'].unique()):
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    unique_currencies = cluster_data['unique_currencies'].mean() if 'unique_currencies' in cluster_data else 0
    ratios = {cat: cluster_data[f'{cat}_spending_ratio'].mean() for cat in categories.keys()}
    ratios.update({ttype: cluster_data[f'{ttype}_spending_ratio'].mean() for ttype in transaction_types.keys()})
    style_spending_ratio = (ratios.get('cosmetic', 0) + ratios.get('fashion', 0) + ratios.get('beauty_salons', 0))
    active_ratios = {
        'auto': ratios.get('auto', 0),
        'style': style_spending_ratio,
        'construction': ratios.get('construction', 0),
        'book_and_sports': ratios.get('book_and_sports', 0),
        'ecom': ratios.get('ecom', 0),
        'pos': ratios.get('pos', 0),
        'cash_withdrawal': ratios.get('cash_withdrawal', 0)
    }
    max_ratio = max(active_ratios.values(), default=0)
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: unique_currencies –¥–ª—è "–ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞", –∏–Ω–∞—á–µ max_ratio
    priority = unique_currencies if unique_currencies > min_currencies_travel else max_ratio
    cluster_priorities.append((cluster_id, priority))

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (—É–±—ã–≤–∞—é—â–∏–π –ø–æ—Ä—è–¥–æ–∫)
cluster_priorities.sort(key=lambda x: x[1], reverse=True)

# –°–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
used_labels = []

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
for cluster_id, priority in cluster_priorities:
    cluster_data = client_features[client_features['cluster'] == cluster_id]
    size = len(cluster_data)
    print(f"\nüîπ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤):")
    cluster_label = interpret_cluster(cluster_data, used_labels, cluster_id)
    print(f"  ‚Ä¢ –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞: {cluster_label}")
    total_avg = cluster_data['total_amount'].mean()
    txn_avg = cluster_data['transaction_count'].mean()
    merchants_avg = cluster_data['unique_merchants'].mean()
    cities_avg = cluster_data['unique_cities'].mean()
    weekend_ratio = cluster_data['weekend_ratio'].mean()
    foreign_txn = cluster_data['has_foreign_txn'].mean()
    unique_currencies = cluster_data['unique_currencies'].mean() if 'unique_currencies' in cluster_data else 0
    print(f"  ‚Ä¢ –û–±—â–∞—è —Å—É–º–º–∞: {total_avg:,.0f} —Ç–µ–Ω–≥–µ")
    print(f"  ‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {txn_avg:.0f}")
    print(f"  ‚Ä¢ –ü—Ä–æ–¥–∞–≤—Ü–æ–≤: {merchants_avg:.1f}")
    print(f"  ‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤: {cities_avg:.1f}")
    print(f"  ‚Ä¢ –î–æ–ª—è –∑–∞–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {foreign_txn:.1%}")
    print(f"  ‚Ä¢ Weekend –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {weekend_ratio:.1%}")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–ª—é—Ç: {unique_currencies:.1f}")
    for cat in categories.keys():
        print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {cat}: {cluster_data[f'{cat}_spending_ratio'].mean():.1%}")
    for ttype in transaction_types.keys():
        print(f"  ‚Ä¢ –î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ {ttype}: {cluster_data[f'{ttype}_spending_ratio'].mean():.1%}")

# 8. –ü–†–û–°–¢–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\nüé® –®–∞–≥ 8: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤', fontsize=14)

colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))
for i in range(optimal_k):
    mask = final_labels == i
    axes[0,0].scatter(X_pca[mask, 0], X_pca[mask, 1],
                     c=[colors[i]], label=f'–ö–ª–∞—Å—Ç–µ—Ä {i}', alpha=0.6, s=20)
axes[0,0].set_title('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ PCA')
axes[0,0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
axes[0,0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
axes[0,0].legend()

cluster_sizes = [sum(final_labels == i) for i in range(optimal_k)]
axes[0,1].bar(range(optimal_k), cluster_sizes, color=colors)
axes[0,1].set_title('–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
axes[0,1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[0,1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤')

cluster_travel = client_features.groupby('cluster')['travel_spending_ratio'].mean()
axes[1,0].bar(cluster_travel.index, cluster_travel.values, color=colors)
axes[1,0].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è')
axes[1,0].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1,0].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')

cluster_auto = client_features.groupby('cluster')['auto_spending_ratio'].mean()
axes[1,1].bar(cluster_auto.index, cluster_auto.values, color=colors)
axes[1,1].set_title('–î–æ–ª—è —Ç—Ä–∞—Ç –Ω–∞ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å—ã')
axes[1,1].set_xlabel('–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞')
axes[1,1].set_ylabel('–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Ç—Ä–∞—Ç')

plt.tight_layout()
plt.show()

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(K_range, inertias, 'bo-')
ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax1.set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
ax1.grid(True)

ax2.plot(K_range, silhouette_scores, 'ro-')
ax2.set_title('–°–∏–ª—É—ç—Ç –∞–Ω–∞–ª–∏–∑')
ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
ax2.set_ylabel('–°–∏–ª—É—ç—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7)
ax2.grid(True)

plt.tight_layout()
plt.show()

# 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\nüíæ –®–∞–≥ 9: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

output_columns = ['card_id', 'total_amount', 'transaction_count', 'unique_merchants',
                 'unique_cities', 'weekend_ratio', 'avg_hour', 'has_foreign_txn',
                 'cluster'] + [f'{cat}_spending_ratio' for cat in categories.keys()] + \
                [f'{ttype}_spending_ratio' for ttype in transaction_types.keys()]
final_results = client_features[output_columns].copy()
final_results['cluster_label'] = final_results['cluster'].apply(
    lambda x: interpret_cluster(client_features[client_features['cluster'] == x], [], x)
)
final_results.to_csv('client_segments.csv', index=False)
print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'client_segments.csv'")

cluster_profiles = client_features.groupby('cluster')[key_profile_features].agg(['mean', 'median']).round(2)
cluster_profiles['cluster_label'] = [interpret_cluster(client_features[client_features['cluster'] == i]) for i in cluster_profiles.index]
cluster_profiles.to_csv('cluster_profiles_summary.csv')
print("‚úÖ –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'cluster_profiles_summary.csv'")